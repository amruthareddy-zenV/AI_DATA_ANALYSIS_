{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Load the Data (Creating Sample Data) ---\n",
      "Initial Sample DataFrame:\n",
      "   ID     Name  Score      City    JoinDate\n",
      "0   1    Alice   85.0  New York  2023-01-10\n",
      "1   2      Bob   92.0    London  2023-01-11\n",
      "2   3  Charlie    NaN     Paris  2023-01-11\n",
      "3   4    David   78.0     Tokyo  2023-01-12\n",
      "4   5      Eve   95.0    Sydney  2023-01-12\n",
      "5   1    Alice   85.0  New York  2023-01-10\n",
      "6   6    Frank   88.0    Berlin  2023-01-13\n",
      "7   7    Grace   91.0    London  2023-01-14\n",
      "8   8    Heidi    NaN     Paris  2023-01-14\n",
      "9   9     Ivan   80.0     Tokyo  2023-01-15\n",
      "\n",
      "\n",
      "--- Step 2.1: Identify Missing Values ---\n",
      "Count of missing values per column:\n",
      "ID          0\n",
      "Name        0\n",
      "Score       2\n",
      "City        0\n",
      "JoinDate    0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Rows with any missing value:\n",
      "   ID     Name  Score   City    JoinDate\n",
      "2   3  Charlie    NaN  Paris  2023-01-11\n",
      "8   8    Heidi    NaN  Paris  2023-01-14\n",
      "\n",
      "\n",
      "--- Step 2.2: Fill Missing Values ---\n",
      "Filled missing 'Score' values with the mean (86.75).\n",
      "DataFrame after filling missing values:\n",
      "   ID     Name  Score      City    JoinDate\n",
      "0   1    Alice  85.00  New York  2023-01-10\n",
      "1   2      Bob  92.00    London  2023-01-11\n",
      "2   3  Charlie  86.75     Paris  2023-01-11\n",
      "3   4    David  78.00     Tokyo  2023-01-12\n",
      "4   5      Eve  95.00    Sydney  2023-01-12\n",
      "5   1    Alice  85.00  New York  2023-01-10\n",
      "6   6    Frank  88.00    Berlin  2023-01-13\n",
      "7   7    Grace  91.00    London  2023-01-14\n",
      "8   8    Heidi  86.75     Paris  2023-01-14\n",
      "9   9     Ivan  80.00     Tokyo  2023-01-15\n",
      "\n",
      "\n",
      "Count of missing values per column after filling:\n",
      "ID          0\n",
      "Name        0\n",
      "Score       0\n",
      "City        0\n",
      "JoinDate    0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "--- Step 3.1: Identify Duplicates ---\n",
      "Boolean Series indicating duplicate rows (keeping first occurrence as False):\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "5     True\n",
      "6    False\n",
      "7    False\n",
      "8    False\n",
      "9    False\n",
      "dtype: bool\n",
      "\n",
      "\n",
      "Identified duplicate rows (showing all occurrences):\n",
      "   ID   Name  Score      City    JoinDate\n",
      "0   1  Alice   85.0  New York  2023-01-10\n",
      "5   1  Alice   85.0  New York  2023-01-10\n",
      "\n",
      "\n",
      "--- Step 3.2: Remove Duplicates ---\n",
      "Removed 1 duplicate rows.\n",
      "DataFrame after removing duplicate rows:\n",
      "   ID     Name  Score      City    JoinDate\n",
      "0   1    Alice  85.00  New York  2023-01-10\n",
      "1   2      Bob  92.00    London  2023-01-11\n",
      "2   3  Charlie  86.75     Paris  2023-01-11\n",
      "3   4    David  78.00     Tokyo  2023-01-12\n",
      "4   5      Eve  95.00    Sydney  2023-01-12\n",
      "6   6    Frank  88.00    Berlin  2023-01-13\n",
      "7   7    Grace  91.00    London  2023-01-14\n",
      "8   8    Heidi  86.75     Paris  2023-01-14\n",
      "9   9     Ivan  80.00     Tokyo  2023-01-15\n",
      "\n",
      "\n",
      "--- Step 4.1: New Sample Data ---\n",
      "New Sample DataFrame:\n",
      "    ProductID ProductName  Price  Stock Supplier\n",
      "0          10           A   10.5  100.0        X\n",
      "1          20           B    NaN   50.0        Y\n",
      "2          30           C    5.0  200.0        Z\n",
      "3          40           D   20.0    NaN        W\n",
      "4          50           E   15.0  150.0        V\n",
      "5          10           A   10.5  100.0        X\n",
      "6          60           F   25.0   80.0        U\n",
      "7          70           G   12.0  120.0        Y\n",
      "8          80           H    NaN   90.0        Z\n",
      "9          90           I   30.0  110.0        W\n",
      "10         20           B    NaN   50.0        Y\n",
      "\n",
      "\n",
      "--- Step 4.2: Handling Missing Values in New Dataset ---\n",
      "Missing values before filling:\n",
      "ProductID      0\n",
      "ProductName    0\n",
      "Price          3\n",
      "Stock          1\n",
      "Supplier       0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Filled missing 'Price' with median (13.50).\n",
      "Filled missing 'Stock' with constant value (0).\n",
      "DataFrame after filling missing values:\n",
      "    ProductID ProductName  Price  Stock Supplier\n",
      "0          10           A   10.5  100.0        X\n",
      "1          20           B   13.5   50.0        Y\n",
      "2          30           C    5.0  200.0        Z\n",
      "3          40           D   20.0    0.0        W\n",
      "4          50           E   15.0  150.0        V\n",
      "5          10           A   10.5  100.0        X\n",
      "6          60           F   25.0   80.0        U\n",
      "7          70           G   12.0  120.0        Y\n",
      "8          80           H   13.5   90.0        Z\n",
      "9          90           I   30.0  110.0        W\n",
      "10         20           B   13.5   50.0        Y\n",
      "\n",
      "\n",
      "Missing values after filling:\n",
      "ProductID      0\n",
      "ProductName    0\n",
      "Price          0\n",
      "Stock          0\n",
      "Supplier       0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "--- Step 4.3: Remove Duplicates from New Dataset ---\n",
      "Identified duplicate rows before removal:\n",
      "    ProductID ProductName  Price  Stock Supplier\n",
      "0          10           A   10.5  100.0        X\n",
      "1          20           B   13.5   50.0        Y\n",
      "5          10           A   10.5  100.0        X\n",
      "10         20           B   13.5   50.0        Y\n",
      "\n",
      "\n",
      "Removed 2 duplicate rows.\n",
      "DataFrame after removing duplicate rows:\n",
      "   ProductID ProductName  Price  Stock Supplier\n",
      "0         10           A   10.5  100.0        X\n",
      "1         20           B   13.5   50.0        Y\n",
      "2         30           C    5.0  200.0        Z\n",
      "3         40           D   20.0    0.0        W\n",
      "4         50           E   15.0  150.0        V\n",
      "6         60           F   25.0   80.0        U\n",
      "7         70           G   12.0  120.0        Y\n",
      "8         80           H   13.5   90.0        Z\n",
      "9         90           I   30.0  110.0        W\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8099/3076763290.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_initial['Score'].fillna(mean_score, inplace=True)\n",
      "/tmp/ipykernel_8099/3076763290.py:130: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_new['Price'].fillna(median_price, inplace=True)\n",
      "/tmp/ipykernel_8099/3076763290.py:134: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_new['Stock'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Part 1: Handle Missing Values & Duplicates\n",
    "\n",
    "    # Step-by-Step Guidelines:\n",
    "# 1. Load the Data: First, ensure you have pandas installed and import it.\n",
    "# 2. Handling Missing Values\n",
    "#     1. Identify Missing Values:\n",
    "#     2. Fill Missing Values:\n",
    "# 3. Handling Duplicates\n",
    "#     1. Identify Duplicates:\n",
    "#     2. Remove Duplicates:\n",
    "# 4. Combined Practice on a New Dataset\n",
    "#     1. New Sample Data:\n",
    "#     2. Handling Missing Values:\n",
    "#     3. Remove Duplicates:\n",
    "        \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Part 1: Handle Missing Values & Duplicates ---\n",
    "# This script demonstrates how to handle missing values and duplicate rows\n",
    "# in a pandas DataFrame following the provided step-by-step guidelines.\n",
    "\n",
    "# --- Step-by-Step Guidelines: ---\n",
    "\n",
    "# 1. Load the Data: First, ensure you have pandas installed and import it.\n",
    "# (Already done at the top of the script)\n",
    "\n",
    "# Create a sample DataFrame for initial demonstration\n",
    "print(\"--- Step 1: Load the Data (Creating Sample Data) ---\")\n",
    "data_initial = {\n",
    "    'ID': [1, 2, 3, 4, 5, 1, 6, 7, 8, 9], # Duplicate ID\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Alice', 'Frank', 'Grace', 'Heidi', 'Ivan'],\n",
    "    'Score': [85, 92, np.nan, 78, 95, 85, 88, 91, np.nan, 80], # Missing Scores\n",
    "    'City': ['New York', 'London', 'Paris', 'Tokyo', 'Sydney', 'New York', 'Berlin', 'London', 'Paris', 'Tokyo'],\n",
    "    'JoinDate': ['2023-01-10', '2023-01-11', '2023-01-11', '2023-01-12', '2023-01-12', '2023-01-10', '2023-01-13', '2023-01-14', '2023-01-14', '2023-01-15']\n",
    "}\n",
    "df_initial = pd.DataFrame(data_initial)\n",
    "\n",
    "print(\"Initial Sample DataFrame:\")\n",
    "print(df_initial)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2. Handling Missing Values\n",
    "\n",
    "# 2.1. Identify Missing Values:\n",
    "print(\"--- Step 2.1: Identify Missing Values ---\")\n",
    "print(\"Count of missing values per column:\")\n",
    "print(df_initial.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Display rows with missing values\n",
    "print(\"Rows with any missing value:\")\n",
    "print(df_initial[df_initial.isnull().any(axis=1)])\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2.2. Fill Missing Values:\n",
    "print(\"--- Step 2.2: Fill Missing Values ---\")\n",
    "\n",
    "# We will fill missing 'Score' values with the mean of the existing scores\n",
    "mean_score = df_initial['Score'].mean()\n",
    "df_initial['Score'].fillna(mean_score, inplace=True)\n",
    "\n",
    "print(f\"Filled missing 'Score' values with the mean ({mean_score:.2f}).\")\n",
    "print(\"DataFrame after filling missing values:\")\n",
    "print(df_initial)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Verify missing values are gone\n",
    "print(\"Count of missing values per column after filling:\")\n",
    "print(df_initial.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# 3. Handling Duplicates\n",
    "\n",
    "# 3.1. Identify Duplicates:\n",
    "print(\"--- Step 3.1: Identify Duplicates ---\")\n",
    "\n",
    "# Identify exact duplicate rows\n",
    "print(\"Boolean Series indicating duplicate rows (keeping first occurrence as False):\")\n",
    "print(df_initial.duplicated())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Show the duplicate rows (keeping all occurrences)\n",
    "print(\"Identified duplicate rows (showing all occurrences):\")\n",
    "print(df_initial[df_initial.duplicated(keep=False)])\n",
    "print(\"\\n\")\n",
    "\n",
    "# 3.2. Remove Duplicates:\n",
    "print(\"--- Step 3.2: Remove Duplicates ---\")\n",
    "\n",
    "# Remove duplicate rows (keeps the first occurrence by default)\n",
    "initial_row_count = len(df_initial)\n",
    "df_initial.drop_duplicates(inplace=True)\n",
    "rows_after_removal = len(df_initial)\n",
    "duplicates_removed = initial_row_count - rows_after_removal\n",
    "\n",
    "print(f\"Removed {duplicates_removed} duplicate rows.\")\n",
    "print(\"DataFrame after removing duplicate rows:\")\n",
    "print(df_initial)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# 4. Combined Practice on a New Dataset\n",
    "\n",
    "# 4.1. New Sample Data:\n",
    "print(\"--- Step 4.1: New Sample Data ---\")\n",
    "data_new = {\n",
    "    'ProductID': [10, 20, 30, 40, 50, 10, 60, 70, 80, 90, 20], # Duplicates\n",
    "    'ProductName': ['A', 'B', 'C', 'D', 'E', 'A', 'F', 'G', 'H', 'I', 'B'],\n",
    "    'Price': [10.5, np.nan, 5.0, 20.0, 15.0, 10.5, 25.0, 12.0, np.nan, 30.0, np.nan], # Missing Prices\n",
    "    'Stock': [100, 50, 200, np.nan, 150, 100, 80, 120, 90, 110, 50], # Missing Stock\n",
    "    'Supplier': ['X', 'Y', 'Z', 'W', 'V', 'X', 'U', 'Y', 'Z', 'W', 'Y']\n",
    "}\n",
    "df_new = pd.DataFrame(data_new)\n",
    "\n",
    "print(\"New Sample DataFrame:\")\n",
    "print(df_new)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 4.2. Handling Missing Values:\n",
    "print(\"--- Step 4.2: Handling Missing Values in New Dataset ---\")\n",
    "\n",
    "print(\"Missing values before filling:\")\n",
    "print(df_new.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Fill missing 'Price' with median\n",
    "median_price = df_new['Price'].median()\n",
    "df_new['Price'].fillna(median_price, inplace=True)\n",
    "print(f\"Filled missing 'Price' with median ({median_price:.2f}).\")\n",
    "\n",
    "# Fill missing 'Stock' with a constant value (e.g., 0)\n",
    "df_new['Stock'].fillna(0, inplace=True)\n",
    "print(\"Filled missing 'Stock' with constant value (0).\")\n",
    "\n",
    "print(\"DataFrame after filling missing values:\")\n",
    "print(df_new)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Missing values after filling:\")\n",
    "print(df_new.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# 4.3. Remove Duplicates:\n",
    "print(\"--- Step 4.3: Remove Duplicates from New Dataset ---\")\n",
    "\n",
    "print(\"Identified duplicate rows before removal:\")\n",
    "print(df_new[df_new.duplicated(keep=False)])\n",
    "print(\"\\n\")\n",
    "\n",
    "initial_row_count_new = len(df_new)\n",
    "df_new.drop_duplicates(inplace=True)\n",
    "rows_after_removal_new = len(df_new)\n",
    "duplicates_removed_new = initial_row_count_new - rows_after_removal_new\n",
    "\n",
    "print(f\"Removed {duplicates_removed_new} duplicate rows.\")\n",
    "print(\"DataFrame after removing duplicate rows:\")\n",
    "print(df_new)\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Conclusion ---\n",
    "# The script demonstrated identifying and handling missing values\n",
    "# and duplicate rows in pandas DataFrames, following the provided steps.\n",
    "# It also showed a combined practice on a new dataset.\n",
    "     \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1.1: Convert All Names to Lowercase ---\n",
      "Original DataFrame (Names):\n",
      "   PersonID           Name  Score\n",
      "0         1    Alice Smith     85\n",
      "1         2    BOB JOHNSON     92\n",
      "2         3  Charlie Brown     78\n",
      "3         4      David Lee     95\n",
      "4         5       Eve Wang     88\n",
      "\n",
      "\n",
      "DataFrame after converting 'Name' to lowercase:\n",
      "   PersonID           Name  Score\n",
      "0         1    alice smith     85\n",
      "1         2    bob johnson     92\n",
      "2         3  charlie brown     78\n",
      "3         4      david lee     95\n",
      "4         5       eve wang     88\n",
      "\n",
      "\n",
      "--- Step 2.1: Round Age Column to the Nearest Integer ---\n",
      "Original DataFrame (Age):\n",
      "   UserID   Age  Height_cm\n",
      "0     101  25.3      165.5\n",
      "1     102  31.9      178.2\n",
      "2     103  45.1      159.8\n",
      "3     104  29.7      170.0\n",
      "4     105  34.5      168.1\n",
      "\n",
      "\n",
      "DataFrame after rounding 'Age' to nearest integer:\n",
      "   UserID  Age  Height_cm\n",
      "0     101   25      165.5\n",
      "1     102   32      178.2\n",
      "2     103   45      159.8\n",
      "3     104   30      170.0\n",
      "4     105   34      168.1\n",
      "\n",
      "\n",
      "--- Step 3.1: New Sample Data ---\n",
      "New Sample DataFrame (Products):\n",
      "   ProductID   ProductName     Price  Stock\n",
      "0       1001    Laptop Pro  1250.756     10\n",
      "1       1002  Gaming Mouse    75.300     50\n",
      "2       1003  USB Keyboard    29.999     15\n",
      "3       1004    4K Monitor   349.500      8\n",
      "4       1005     Webcam HD    55.000     25\n",
      "\n",
      "\n",
      "--- Step 3.2: Standardize Product Names ---\n",
      "DataFrame after standardizing 'ProductName' to lowercase:\n",
      "   ProductID   ProductName     Price  Stock\n",
      "0       1001    laptop pro  1250.756     10\n",
      "1       1002  gaming mouse    75.300     50\n",
      "2       1003  usb keyboard    29.999     15\n",
      "3       1004    4k monitor   349.500      8\n",
      "4       1005     webcam hd    55.000     25\n",
      "\n",
      "\n",
      "--- Step 3.3: Format Prices to Two Decimal Places ---\n",
      "DataFrame after formatting 'Price' to two decimal places:\n",
      "   ProductID   ProductName    Price  Stock\n",
      "0       1001    laptop pro  1250.76     10\n",
      "1       1002  gaming mouse    75.30     50\n",
      "2       1003  usb keyboard    30.00     15\n",
      "3       1004    4k monitor   349.50      8\n",
      "4       1005     webcam hd    55.00     25\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Part 2: Apply Standardization & Formatting Rules\n",
    "\n",
    "#     Step-by-Step Guidelines:\n",
    "# 1. Standardize Text Data\n",
    "#     1. Convert All Names to Lowercase:\n",
    "# 2. Format Numerical Data\n",
    "#     1. Round Age Column to the Nearest Integer:\n",
    "# 3. Combined Practice on Another Dataset\n",
    "#     1. New Sample Data:\n",
    "#     2. Standardize Product Names:\n",
    "#     3. Format Prices to Two Decimal Places:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Part 2: Apply Standardization & Formatting Rules ---\n",
    "# This script demonstrates how to standardize text data and format numerical data\n",
    "# in a pandas DataFrame following the provided step-by-step guidelines.\n",
    "\n",
    "# --- Step-by-Step Guidelines: ---\n",
    "\n",
    "# 1. Standardize Text Data\n",
    "\n",
    "# 1.1. Convert All Names to Lowercase:\n",
    "print(\"--- Step 1.1: Convert All Names to Lowercase ---\")\n",
    "\n",
    "# Create a sample DataFrame with a Name column\n",
    "data_names = {\n",
    "    'PersonID': [1, 2, 3, 4, 5],\n",
    "    'Name': ['Alice Smith', 'BOB JOHNSON', 'Charlie Brown', 'David Lee', 'Eve Wang'],\n",
    "    'Score': [85, 92, 78, 95, 88]\n",
    "}\n",
    "df_names = pd.DataFrame(data_names)\n",
    "\n",
    "print(\"Original DataFrame (Names):\")\n",
    "print(df_names)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Convert the 'Name' column to lowercase\n",
    "df_names['Name'] = df_names['Name'].str.lower()\n",
    "\n",
    "print(\"DataFrame after converting 'Name' to lowercase:\")\n",
    "print(df_names)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2. Format Numerical Data\n",
    "\n",
    "# 2.1. Round Age Column to the Nearest Integer:\n",
    "print(\"--- Step 2.1: Round Age Column to the Nearest Integer ---\")\n",
    "\n",
    "# Create a sample DataFrame with an Age column (potentially with decimals)\n",
    "data_age = {\n",
    "    'UserID': [101, 102, 103, 104, 105],\n",
    "    'Age': [25.3, 31.9, 45.1, 29.7, 34.5],\n",
    "    'Height_cm': [165.5, 178.2, 159.8, 170.0, 168.1]\n",
    "}\n",
    "df_age = pd.DataFrame(data_age)\n",
    "\n",
    "print(\"Original DataFrame (Age):\")\n",
    "print(df_age)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Round the 'Age' column to the nearest integer\n",
    "# Use .round(0) and then .astype(int) to convert to integer type\n",
    "df_age['Age'] = df_age['Age'].round(0).astype(int)\n",
    "\n",
    "print(\"DataFrame after rounding 'Age' to nearest integer:\")\n",
    "print(df_age)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 3. Combined Practice on Another Dataset\n",
    "\n",
    "# 3.1. New Sample Data:\n",
    "print(\"--- Step 3.1: New Sample Data ---\")\n",
    "\n",
    "# Create a new sample DataFrame with Product Names and Prices\n",
    "data_products = {\n",
    "    'ProductID': [1001, 1002, 1003, 1004, 1005],\n",
    "    'ProductName': ['Laptop Pro', 'Gaming Mouse', 'USB Keyboard', '4K Monitor', 'Webcam HD'], # Mixed casing\n",
    "    'Price': [1250.756, 75.3, 29.999, 349.5, 55.0], # Varying decimal places\n",
    "    'Stock': [10, 50, 15, 8, 25]\n",
    "}\n",
    "df_products = pd.DataFrame(data_products)\n",
    "\n",
    "print(\"New Sample DataFrame (Products):\")\n",
    "print(df_products)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 3.2. Standardize Product Names:\n",
    "print(\"--- Step 3.2: Standardize Product Names ---\")\n",
    "\n",
    "# Convert the 'ProductName' column to lowercase\n",
    "df_products['ProductName'] = df_products['ProductName'].str.lower()\n",
    "\n",
    "print(\"DataFrame after standardizing 'ProductName' to lowercase:\")\n",
    "print(df_products)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 3.3. Format Prices to Two Decimal Places:\n",
    "print(\"--- Step 3.3: Format Prices to Two Decimal Places ---\")\n",
    "\n",
    "# Round the 'Price' column to two decimal places\n",
    "# Use .round(2)\n",
    "df_products['Price'] = df_products['Price'].round(2)\n",
    "\n",
    "print(\"DataFrame after formatting 'Price' to two decimal places:\")\n",
    "print(df_products)\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Conclusion ---\n",
    "# The script demonstrated standardizing text data by converting to lowercase\n",
    "# and formatting numerical data by rounding to the nearest integer and\n",
    "# to a specific number of decimal places, following the provided steps.\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
