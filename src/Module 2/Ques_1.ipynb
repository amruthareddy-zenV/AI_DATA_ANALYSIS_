{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'your_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# 2. Load a CSV file into a DataFrame\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Replace 'your_data.csv' with your actual file path\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myour_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# If you don't have a CSV file, you can use this sample data:\u001b[39;00m\n\u001b[1;32m     31\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBob\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCharlie\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m35\u001b[39m],\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNew York\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLondon\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParis\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n",
      "File \u001b[0;32m/workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_data.csv'"
     ]
    }
   ],
   "source": [
    "# Getting Started with Pandas\n",
    "# Objective: Introduce students to using Pandas for data analysis by loading data into Pandas\n",
    "# DataFrames.\n",
    "\n",
    "# Question 1: Importing Pandas and Loading a CSV File\n",
    "# 1. Open your Jupyter Notebook or a Python environment.\n",
    "# 2. Import the pandas library.\n",
    "# 3. Load a CSV file into a DataFrame.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 2: Displaying the First Few Rows\n",
    "# 4. Use the head() method to display the first five rows of the DataFrame.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 3: Basic Data Information\n",
    "# 5. Use the info() method to get a concise summary of the DataFrame.\n",
    "# Question 1: Importing Pandas and Loading a CSV File\n",
    "# 1. Import pandas (conventionally imported as pd)\n",
    "import pandas as pd\n",
    "\n",
    "# 2. Load a CSV file into a DataFrame\n",
    "# Replace 'your_data.csv' with your actual file path\n",
    "df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# If you don't have a CSV file, you can use this sample data:\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Age': [25, 30, 35],\n",
    "        'City': ['New York', 'London', 'Paris']}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"DataFrame created successfully!\")\n",
    "\n",
    "# Question 2: Displaying the First Few Rows\n",
    "# 3. Display first five rows using head()\n",
    "print(\"\\nFirst 5 rows of the DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Question 3: Basic Data Information\n",
    "# 4. Get DataFrame summary using info()\n",
    "print(\"\\nDataFrame information:\")\n",
    "print(df.info())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of each column:\n",
      "Name      object\n",
      "Age        int64\n",
      "City      object\n",
      "Salary     int64\n",
      "dtype: object\n",
      "\n",
      "Selected column (Name):\n",
      "0      Alice\n",
      "1        Bob\n",
      "2    Charlie\n",
      "3      David\n",
      "4        Eve\n",
      "Name: Name, dtype: object\n",
      "\n",
      "Selected column (Age):\n",
      "0    25\n",
      "1    30\n",
      "2    35\n",
      "3    28\n",
      "4    32\n",
      "Name: Age, dtype: int64\n",
      "\n",
      "Rows 1 to 3:\n",
      "      Name  Age    City  Salary\n",
      "1      Bob   30  London   60000\n",
      "2  Charlie   35   Paris   70000\n",
      "3    David   28   Tokyo   55000\n",
      "\n",
      "Rows 0 and 2:\n",
      "      Name  Age      City  Salary\n",
      "0    Alice   25  New York   50000\n",
      "2  Charlie   35     Paris   70000\n"
     ]
    }
   ],
   "source": [
    "# Data Inspection & Selection\n",
    "# Objective: Learn how to inspect data and select specific data points.\n",
    "\n",
    "# Question 1: Inspecting Column Data Types\n",
    "# 6. Use the dtypes attribute to inspect the data types of each column.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 2: Selecting Columns\n",
    "# 7. Select a single column from the DataFrame.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 3: Slicing Rows\n",
    "# 8. Select specific rows using slicing.\n",
    "\n",
    "# Import pandas (if not already imported)\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame (or use your existing DataFrame)\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Age': [25, 30, 35, 28, 32],\n",
    "    'City': ['New York', 'London', 'Paris', 'Tokyo', 'Sydney'],\n",
    "    'Salary': [50000, 60000, 70000, 55000, 65000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Question 1: Inspecting Column Data Types\n",
    "print(\"Data types of each column:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Question 2: Selecting Columns\n",
    "# Method 1: Using dictionary-style notation\n",
    "names = df['Name']\n",
    "print(\"\\nSelected column (Name):\")\n",
    "print(names)\n",
    "\n",
    "# Method 2: Using dot notation (only works with column names without spaces)\n",
    "ages = df.Age\n",
    "print(\"\\nSelected column (Age):\")\n",
    "print(ages)\n",
    "\n",
    "# Question 3: Slicing Rows\n",
    "# Select rows 1 to 3 (remember Python uses 0-based indexing)\n",
    "sliced_rows = df[1:4]\n",
    "print(\"\\nRows 1 to 3:\")\n",
    "print(sliced_rows)\n",
    "\n",
    "# Select specific rows by index (rows 0 and 2)\n",
    "specific_rows = df.iloc[[0, 2]]\n",
    "print(\"\\nRows 0 and 2:\")\n",
    "print(specific_rows)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   CustomerID   Name   Age  PurchaseAmount\n",
      "0         101  Alice  25.0           150.0\n",
      "1         102    Bob  30.0           200.0\n",
      "2         103    NaN   NaN             NaN\n",
      "3         104  David  28.0           180.0\n",
      "4         102    Bob  30.0           200.0\n",
      "5         105    Eve  32.0           220.0\n",
      "\n",
      "DataFrame after filling missing values:\n",
      "   CustomerID     Name   Age  PurchaseAmount\n",
      "0         101    Alice  25.0           150.0\n",
      "1         102      Bob  30.0           200.0\n",
      "2         103  Unknown  30.0           190.0\n",
      "3         104    David  28.0           180.0\n",
      "4         102      Bob  30.0           200.0\n",
      "5         105      Eve  32.0           220.0\n",
      "\n",
      "DataFrame after renaming columns:\n",
      "    ID CustomerName  CustomerAge  Amount\n",
      "0  101        Alice         25.0   150.0\n",
      "1  102          Bob         30.0   200.0\n",
      "2  103      Unknown         30.0   190.0\n",
      "3  104        David         28.0   180.0\n",
      "4  102          Bob         30.0   200.0\n",
      "5  105          Eve         32.0   220.0\n",
      "\n",
      "DataFrame after removing duplicates:\n",
      "    ID CustomerName  CustomerAge  Amount\n",
      "0  101        Alice         25.0   150.0\n",
      "1  102          Bob         30.0   200.0\n",
      "2  103      Unknown         30.0   190.0\n",
      "3  104        David         28.0   180.0\n",
      "5  105          Eve         32.0   220.0\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning & Manipulation\n",
    "# Objective: Practice cleaning data and manipulating DataFrames.\n",
    "\n",
    "# Question 1: Handling Missing Values\n",
    "# 9. Use the fillna() method to fill missing values with a specific value.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# QUestion 2: Renaming Columns\n",
    "# 10. Change the names of specific columns using rename().\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 3: Dropping Duplicates\n",
    "# 11. Remove duplicate rows from the DataFrame.\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample DataFrame with missing values and duplicates\n",
    "data = {\n",
    "    'CustomerID': [101, 102, 103, 104, 102, 105],\n",
    "    'Name': ['Alice', 'Bob', np.nan, 'David', 'Bob', 'Eve'],\n",
    "    'Age': [25, 30, np.nan, 28, 30, 32],\n",
    "    'PurchaseAmount': [150.0, 200.0, np.nan, 180.0, 200.0, 220.0]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Question 1: Handling Missing Values\n",
    "# Fill numeric columns with median and string columns with 'Unknown'\n",
    "df_filled = df.copy()\n",
    "df_filled['Age'] = df_filled['Age'].fillna(df_filled['Age'].median())\n",
    "df_filled['Name'] = df_filled['Name'].fillna('Unknown')\n",
    "df_filled['PurchaseAmount'] = df_filled['PurchaseAmount'].fillna(df_filled['PurchaseAmount'].mean())\n",
    "\n",
    "print(\"\\nDataFrame after filling missing values:\")\n",
    "print(df_filled)\n",
    "\n",
    "# Question 2: Renaming Columns\n",
    "# Rename columns to be more descriptive\n",
    "df_renamed = df_filled.rename(columns={\n",
    "    'CustomerID': 'ID',\n",
    "    'Name': 'CustomerName',\n",
    "    'Age': 'CustomerAge',\n",
    "    'PurchaseAmount': 'Amount'\n",
    "})\n",
    "\n",
    "print(\"\\nDataFrame after renaming columns:\")\n",
    "print(df_renamed)\n",
    "\n",
    "# Question 3: Dropping Duplicates\n",
    "# Keep the first occurrence of duplicate rows\n",
    "df_clean = df_renamed.drop_duplicates()\n",
    "\n",
    "print(\"\\nDataFrame after removing duplicates:\")\n",
    "print(df_clean)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  Department Employee  Salary  Experience\n",
      "0      Sales    Alice   60000           3\n",
      "1         IT      Bob   80000           5\n",
      "2      Sales  Charlie   55000           2\n",
      "3         HR    David   45000           1\n",
      "4         IT      Eve   90000           7\n",
      "5         HR    Frank   50000           1\n",
      "6      Sales    Grace   62000           4\n",
      "7         IT    Heidi   85000           6\n",
      "\n",
      "Average salary by department:\n",
      "Department\n",
      "HR       47500.0\n",
      "IT       85000.0\n",
      "Sales    59000.0\n",
      "Name: Salary, dtype: float64\n",
      "\n",
      "Saved department salary statistics to 'department_salary_stats.csv'\n",
      "\n",
      "Comprehensive department statistics:\n",
      "             Salary                            Experience      \n",
      "               mean    min    max          std       mean count\n",
      "Department                                                     \n",
      "HR          47500.0  45000  50000  3535.533906        1.0     2\n",
      "IT          85000.0  80000  90000  5000.000000        6.0     3\n",
      "Sales       59000.0  55000  62000  3605.551275        3.0     3\n",
      "Saved comprehensive department statistics to 'department_full_stats.csv'\n"
     ]
    }
   ],
   "source": [
    "# Data Aggregation & Exporting\n",
    "# Objective: Aggregate data and export the results.\n",
    "\n",
    "# Question 1: Grouping and Aggregating Data\n",
    "# 12. Group data by a specific column and calculate the mean for each group.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 2: Exporting Data to CSV\n",
    "# 13. Export the DataFrame to a new CSV file.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 3: Aggregating with Multiple Functions\n",
    "# 14. Apply several aggregate functions to the grouped data.\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'Department': ['Sales', 'IT', 'Sales', 'HR', 'IT', 'HR', 'Sales', 'IT'],\n",
    "    'Employee': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank', 'Grace', 'Heidi'],\n",
    "    'Salary': [60000, 80000, 55000, 45000, 90000, 50000, 62000, 85000],\n",
    "    'Experience': [3, 5, 2, 1, 7, 1, 4, 6]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Question 1: Grouping and Aggregating Data\n",
    "# Group by Department and calculate mean salary\n",
    "dept_stats = df.groupby('Department')['Salary'].mean()\n",
    "print(\"\\nAverage salary by department:\")\n",
    "print(dept_stats)\n",
    "\n",
    "# Question 2: Exporting Data to CSV\n",
    "# Export the grouped results to a new CSV file\n",
    "dept_stats.to_csv('department_salary_stats.csv', header=['AverageSalary'])\n",
    "print(\"\\nSaved department salary statistics to 'department_salary_stats.csv'\")\n",
    "\n",
    "# Question 3: Aggregating with Multiple Functions\n",
    "# Group by Department and calculate multiple statistics\n",
    "dept_full_stats = df.groupby('Department').agg({\n",
    "    'Salary': ['mean', 'min', 'max', 'std'],\n",
    "    'Experience': ['mean', 'count']\n",
    "})\n",
    "\n",
    "print(\"\\nComprehensive department statistics:\")\n",
    "print(dept_full_stats)\n",
    "\n",
    "# Export the comprehensive statistics\n",
    "dept_full_stats.to_csv('department_full_stats.csv')\n",
    "print(\"Saved comprehensive department statistics to 'department_full_stats.csv'\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
