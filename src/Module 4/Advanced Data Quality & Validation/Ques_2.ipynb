{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original DataFrame Head ---\n",
      "   numerical_feature_1  numerical_feature_2 categorical_feature_1  \\\n",
      "0            10.993428            61.801447                     A   \n",
      "1             9.723471            97.395434                     B   \n",
      "2            11.295377            91.010028                     C   \n",
      "3            13.046060            61.914344                     A   \n",
      "4             9.531693            54.163188                     B   \n",
      "\n",
      "  categorical_feature_2    target  \n",
      "0                     Y  0.464239  \n",
      "1                     X  0.722738  \n",
      "2                     X  0.656729  \n",
      "3                     X  0.708766  \n",
      "4                     X  0.008364  \n",
      "\n",
      "\n",
      "--- Drifted DataFrame Head ---\n",
      "   numerical_feature_1  numerical_feature_2 categorical_feature_1  \\\n",
      "0             7.125586            44.768947                     C   \n",
      "1            12.356701            96.674478                     A   \n",
      "2            14.382590            90.422237                     C   \n",
      "3            10.868910            60.891241                     B   \n",
      "4            13.953302            72.805240                     C   \n",
      "\n",
      "  categorical_feature_2    target  \n",
      "0                     X  0.821002  \n",
      "1                     X  0.691213  \n",
      "2                     X  0.971189  \n",
      "3                     X  0.552817  \n",
      "4                     X  0.380214  \n",
      "\n",
      "\n",
      "--- Monitoring Features for Data Drift ---\n",
      "\n",
      "Checking feature: 'numerical_feature_1'\n",
      "  Type: Numerical\n",
      "  Basic Stats Diff (Mean: 1.47, Std Dev: 0.62)\n",
      "  Potential drift detected based on basic stats thresholds.\n",
      "  KS Test (Statistic: 0.2840, P-value: 0.0000)\n",
      "  Significant drift detected based on KS test (p < 0.05).\n",
      "\n",
      "Checking feature: 'numerical_feature_2'\n",
      "  Type: Numerical\n",
      "  Basic Stats Diff (Mean: 15.21, Std Dev: 4.88)\n",
      "  Potential drift detected based on basic stats thresholds.\n",
      "  KS Test (Statistic: 0.3840, P-value: 0.0000)\n",
      "  Significant drift detected based on KS test (p < 0.05).\n",
      "\n",
      "Checking feature: 'categorical_feature_1'\n",
      "  Type: Categorical\n",
      "  Comparing category frequencies...\n",
      "  Potential drift detected based on significant category proportion changes.\n",
      "    Details: {'A': 0.22800000000000004, 'C': 0.132}\n",
      "\n",
      "Checking feature: 'categorical_feature_2'\n",
      "  Type: Categorical\n",
      "  Comparing category frequencies...\n",
      "  Potential drift detected based on significant category proportion changes.\n",
      "    Details: {'X': 0.118, 'Y': 0.118}\n",
      "\n",
      "Checking feature: 'target'\n",
      "  Type: Numerical\n",
      "  Basic Stats Diff (Mean: 0.00, Std Dev: 0.00)\n",
      "  KS Test (Statistic: 0.0400, P-value: 0.8192)\n",
      "  No significant drift detected based on KS test (p >= 0.05).\n",
      "\n",
      "--- Summary of Features with Potential Drift ---\n",
      "The following features show potential signs of data drift:\n",
      "- numerical_feature_1\n",
      "- numerical_feature_2\n",
      "- categorical_feature_1\n",
      "- categorical_feature_2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "# Suppress potential warnings from SciPy KS test with identical data\n",
    "warnings.filterwarnings(\"ignore\", message=\"p-value may be inaccurate\")\n",
    "\n",
    "# --- Introduction ---\n",
    "# This script demonstrates how to monitor feature distribution changes\n",
    "# using Python to detect potential data drift.\n",
    "# We will use both basic statistics and the Kolmogorov-Smirnov (KS) test.\n",
    "#\n",
    "# We will:\n",
    "# 1. Create sample \"original\" and \"drifted\" DataFrames.\n",
    "# 2. Define a function to compare statistics (mean, std dev) for numerical features.\n",
    "# 3. Define a function to perform the KS test for numerical features.\n",
    "# 4. Define a function to compare frequencies for categorical features (using Chi-squared test - conceptual here, KS is for continuous).\n",
    "# 5. Iterate through features and apply relevant checks.\n",
    "# 6. Report features exhibiting potential drift based on thresholds/p-values.\n",
    "\n",
    "# --- 1. Create Sample DataFrames ---\n",
    "# Create a sample original DataFrame\n",
    "np.random.seed(42)\n",
    "original_data = {\n",
    "    'numerical_feature_1': np.random.normal(loc=10, scale=2, size=500),\n",
    "    'numerical_feature_2': np.random.beta(a=5, b=1, size=500) * 100, # Beta distribution\n",
    "    'categorical_feature_1': np.random.choice(['A', 'B', 'C'], size=500, p=[0.5, 0.3, 0.2]),\n",
    "    'categorical_feature_2': np.random.choice(['X', 'Y'], size=500, p=[0.7, 0.3]),\n",
    "    'target': np.random.rand(500) # Example target, not used for feature drift\n",
    "}\n",
    "original_df = pd.DataFrame(original_data)\n",
    "\n",
    "print(\"--- Original DataFrame Head ---\")\n",
    "print(original_df.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Create a sample drifted DataFrame - introduce changes\n",
    "np.random.seed(100) # Different seed for drifted data\n",
    "drifted_data = {\n",
    "    'numerical_feature_1': np.random.normal(loc=11.5, scale=2.5, size=500), # Shifted mean, increased std dev\n",
    "    'numerical_feature_2': np.random.beta(a=3, b=1.5, size=500) * 100, # Changed beta parameters\n",
    "    'categorical_feature_1': np.random.choice(['A', 'B', 'C'], size=500, p=[0.3, 0.4, 0.3]), # Changed proportions\n",
    "    'categorical_feature_2': np.random.choice(['X', 'Y'], size=500, p=[0.6, 0.4]), # Changed proportions\n",
    "    'target': np.random.rand(500) # Example target\n",
    "}\n",
    "drifted_df = pd.DataFrame(drifted_data)\n",
    "\n",
    "print(\"--- Drifted DataFrame Head ---\")\n",
    "print(drifted_df.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- 2. Function to Compare Basic Statistics ---\n",
    "def compare_basic_stats(original_series, drifted_series, threshold_mean=0.5, threshold_std=0.3):\n",
    "    \"\"\"\n",
    "    Compares mean and standard deviation between two numerical series.\n",
    "\n",
    "    Args:\n",
    "        original_series (pd.Series): The original data series.\n",
    "        drifted_series (pd.Series): The drifted data series.\n",
    "        threshold_mean (float): Absolute difference in mean to flag as potential drift.\n",
    "        threshold_std (float): Absolute difference in std dev to flag as potential drift.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary reporting the differences and if thresholds are exceeded.\n",
    "    \"\"\"\n",
    "    mean_orig = original_series.mean()\n",
    "    std_orig = original_series.std()\n",
    "    mean_drift = drifted_series.mean()\n",
    "    std_drift = drifted_series.std()\n",
    "\n",
    "    mean_diff = abs(mean_drift - mean_orig)\n",
    "    std_diff = abs(std_drift - std_orig)\n",
    "\n",
    "    report = {\n",
    "        'mean_original': mean_orig,\n",
    "        'std_original': std_orig,\n",
    "        'mean_drifted': mean_drift,\n",
    "        'std_drifted': std_drift,\n",
    "        'mean_difference': mean_diff,\n",
    "        'std_difference': std_diff,\n",
    "        'mean_drift_detected': mean_diff > threshold_mean,\n",
    "        'std_drift_detected': std_diff > threshold_std\n",
    "    }\n",
    "    return report\n",
    "\n",
    "# --- 3. Function to Perform KS Test ---\n",
    "def perform_ks_test(original_series, drifted_series, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Performs the two-sample Kolmogorov-Smirnov test.\n",
    "\n",
    "    Args:\n",
    "        original_series (pd.Series): The original data series.\n",
    "        drifted_series (pd.Series): The drifted data series.\n",
    "        alpha (float): Significance level for the test.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary reporting the KS statistic, p-value, and drift detection result.\n",
    "    \"\"\"\n",
    "    # Ensure no NaNs as KS test doesn't handle them\n",
    "    original_clean = original_series.dropna()\n",
    "    drifted_clean = drifted_series.dropna()\n",
    "\n",
    "    if len(original_clean) < 2 or len(drifted_clean) < 2:\n",
    "         return {'error': 'Not enough non-null data for KS test'}\n",
    "\n",
    "\n",
    "    ks_statistic, p_value = stats.ks_2samp(original_clean, drifted_clean)\n",
    "\n",
    "    report = {\n",
    "        'ks_statistic': ks_statistic,\n",
    "        'p_value': p_value,\n",
    "        'drift_detected_ks': p_value < alpha,\n",
    "        'alpha': alpha\n",
    "    }\n",
    "    return report\n",
    "\n",
    "# --- 4. Function to Compare Frequencies (Conceptual for Categorical) ---\n",
    "# Note: KS test is for continuous data. For categorical data,\n",
    "# Chi-squared test is more appropriate. This function is a placeholder\n",
    "# and would require implementing or using scipy.stats.chi2_contingency.\n",
    "def compare_categorical_frequencies(original_series, drifted_series, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Compares frequency distributions for categorical data (Conceptual - Chi-squared needed).\n",
    "\n",
    "    Args:\n",
    "        original_series (pd.Series): The original data series.\n",
    "        drifted_series (pd.Series): The drifted data series.\n",
    "        alpha (float): Significance level for the test.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary reporting potential drift based on frequency changes.\n",
    "    \"\"\"\n",
    "    # Get value counts and normalize for comparison\n",
    "    orig_counts = original_series.value_counts(normalize=True)\n",
    "    drift_counts = drifted_series.value_counts(normalize=True)\n",
    "\n",
    "    # Combine indices to ensure all categories are considered\n",
    "    all_categories = orig_counts.index.union(drift_counts.index)\n",
    "\n",
    "    # Reindex to align and fill missing categories with 0\n",
    "    orig_aligned = orig_counts.reindex(all_categories, fill_value=0)\n",
    "    drift_aligned = drift_counts.reindex(all_categories, fill_value=0)\n",
    "\n",
    "    # Calculate absolute differences in proportions\n",
    "    proportion_diffs = abs(orig_aligned - drift_aligned)\n",
    "\n",
    "    # Simple check: flag if any proportion difference exceeds a threshold (e.g., 10%)\n",
    "    # A more robust method would use Chi-squared test (scipy.stats.chi2_contingency)\n",
    "    # or other statistical distance metrics (e.g., Total Variation Distance).\n",
    "    threshold_proportion_diff = 0.10\n",
    "    significant_changes = proportion_diffs[proportion_diffs > threshold_proportion_diff]\n",
    "\n",
    "    report = {\n",
    "        'original_proportions': orig_counts.to_dict(),\n",
    "        'drifted_proportions': drift_counts.to_dict(),\n",
    "        'proportion_differences': proportion_diffs.to_dict(),\n",
    "        'significant_proportion_changes_detected': not significant_changes.empty,\n",
    "        'significant_changes_details': significant_changes.to_dict() if not significant_changes.empty else {}\n",
    "    }\n",
    "    return report\n",
    "\n",
    "\n",
    "# --- 5. Iterate Through Features and Apply Checks ---\n",
    "print(\"--- Monitoring Features for Data Drift ---\")\n",
    "\n",
    "drift_report = {}\n",
    "alpha_ks = 0.05 # Significance level for KS test\n",
    "basic_stats_mean_threshold = 0.5 # Threshold for mean difference\n",
    "basic_stats_std_threshold = 0.3  # Threshold for std dev difference\n",
    "\n",
    "# Assume both dataframes have the same columns for simplicity in this example\n",
    "for col in original_df.columns:\n",
    "    print(f\"\\nChecking feature: '{col}'\")\n",
    "    drift_report[col] = {}\n",
    "\n",
    "    if pd.api.types.is_numeric_dtype(original_df[col].dtype):\n",
    "        print(\"  Type: Numerical\")\n",
    "        # Perform basic statistics comparison\n",
    "        stats_report = compare_basic_stats(\n",
    "            original_df[col],\n",
    "            drifted_df[col],\n",
    "            threshold_mean=basic_stats_mean_threshold,\n",
    "            threshold_std=basic_stats_std_threshold\n",
    "        )\n",
    "        drift_report[col]['basic_stats'] = stats_report\n",
    "        print(f\"  Basic Stats Diff (Mean: {stats_report['mean_difference']:.2f}, Std Dev: {stats_report['std_difference']:.2f})\")\n",
    "        if stats_report['mean_drift_detected'] or stats_report['std_drift_detected']:\n",
    "             print(\"  Potential drift detected based on basic stats thresholds.\")\n",
    "\n",
    "        # Perform KS test\n",
    "        ks_report = perform_ks_test(original_df[col], drifted_df[col], alpha=alpha_ks)\n",
    "        drift_report[col]['ks_test'] = ks_report\n",
    "        if 'error' in ks_report:\n",
    "            print(f\"  KS Test Error: {ks_report['error']}\")\n",
    "        else:\n",
    "            print(f\"  KS Test (Statistic: {ks_report['ks_statistic']:.4f}, P-value: {ks_report['p_value']:.4f})\")\n",
    "            if ks_report['drift_detected_ks']:\n",
    "                print(f\"  Significant drift detected based on KS test (p < {alpha_ks}).\")\n",
    "            else:\n",
    "                 print(f\"  No significant drift detected based on KS test (p >= {alpha_ks}).\")\n",
    "\n",
    "    elif original_df[col].dtype == 'object' or pd.api.types.is_categorical_dtype(original_df[col].dtype):\n",
    "        print(\"  Type: Categorical\")\n",
    "        # Perform categorical frequency comparison (Conceptual)\n",
    "        freq_report = compare_categorical_frequencies(original_df[col], drifted_df[col])\n",
    "        drift_report[col]['categorical_freq'] = freq_report\n",
    "        print(\"  Comparing category frequencies...\")\n",
    "        if freq_report['significant_proportion_changes_detected']:\n",
    "             print(f\"  Potential drift detected based on significant category proportion changes.\")\n",
    "             print(f\"    Details: {freq_report['significant_changes_details']}\")\n",
    "        else:\n",
    "             print(\"  No significant category proportion changes detected (based on simple threshold).\")\n",
    "\n",
    "    else:\n",
    "        print(f\"  Type: {original_df[col].dtype} - Monitoring not implemented for this type.\")\n",
    "        drift_report[col]['status'] = 'Monitoring not implemented for this type'\n",
    "\n",
    "\n",
    "# --- 6. Report Features Exhibiting Potential Drift ---\n",
    "print(\"\\n--- Summary of Features with Potential Drift ---\")\n",
    "features_with_drift = []\n",
    "\n",
    "for col, report in drift_report.items():\n",
    "    is_drifted = False\n",
    "    if 'basic_stats' in report and (report['basic_stats'].get('mean_drift_detected') or report['basic_stats'].get('std_drift_detected')):\n",
    "        is_drifted = True\n",
    "    if 'ks_test' in report and report['ks_test'].get('drift_detected_ks'):\n",
    "        is_drifted = True\n",
    "    if 'categorical_freq' in report and report['categorical_freq'].get('significant_proportion_changes_detected'):\n",
    "         is_drifted = True\n",
    "\n",
    "    if is_drifted:\n",
    "        features_with_drift.append(col)\n",
    "\n",
    "if features_with_drift:\n",
    "    print(\"The following features show potential signs of data drift:\")\n",
    "    for feature in features_with_drift:\n",
    "        print(f\"- {feature}\")\n",
    "else:\n",
    "    print(\"No significant data drift detected in any feature based on the checks performed.\")\n",
    "\n",
    "# You can inspect the full drift_report dictionary for detailed results per feature\n",
    "# print(\"\\n--- Full Drift Report ---\")\n",
    "# import json\n",
    "# print(json.dumps(drift_report, indent=2))\n",
    "\n",
    "# --- Conclusion ---\n",
    "# This script provides a framework for monitoring data drift by comparing\n",
    "# feature distributions using basic statistics and the KS test.\n",
    "# For a production system, you would integrate this logic into your monitoring\n",
    "# pipeline and potentially use more sophisticated libraries like Evidently,\n",
    "# Deepchecks, or Fiddler for comprehensive drift detection and reporting.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Sample DataFrame ---\n",
      "   ProductID ProductName     Category    Price  StockQuantity  ReleaseDate  \\\n",
      "0        101      Laptop  Electronics  1200.50             10   2023-01-10   \n",
      "1        102    Keyboard  Electronics    75.00             50   2023-01-11   \n",
      "2        103       Mouse  Electronics    25.99              0   2023-01-11   \n",
      "3        104     Monitor  Electronics   300.00             15   2023-01-12   \n",
      "4        105      Webcam  Electronics   -50.00             25   2023-01-12   \n",
      "5        106     Printer  Electronics   250.00              5   2023-01-13   \n",
      "6        107     Speaker        Audio   150.00             12   2023-01-13   \n",
      "7        108  Headphones          NaN    99.50             30   2023-01-14   \n",
      "8        109  Microphone        Audio    70.00              8   2023-01-14   \n",
      "9        110      Router      Network    80.00             20  InvalidDate   \n",
      "\n",
      "   IsActive  \n",
      "0      True  \n",
      "1     False  \n",
      "2      True  \n",
      "3      True  \n",
      "4     False  \n",
      "5      True  \n",
      "6      True  \n",
      "7     False  \n",
      "8      True  \n",
      "9      True  \n",
      "\n",
      "\n",
      "--- Applying Validation Checks ---\n",
      "--- Data Validation Report ---\n",
      "Validation Failed: The following data quality issues were detected:\n",
      "- Column 'Category': Contains 1 missing values, but is required.\n",
      "- Column 'Price': Value range violations: Contains 1 values below the minimum (0.0).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Introduction ---\n",
    "# This script demonstrates setting up basic automated data validation\n",
    "# using pure Python and the pandas library.\n",
    "# It covers checks for missing values, data types, and value ranges.\n",
    "#\n",
    "# We will:\n",
    "# 1. Create a sample DataFrame with some data quality issues.\n",
    "# 2. Define validation functions for different types of checks.\n",
    "# 3. Apply these validation functions to the DataFrame.\n",
    "# 4. Report the validation results.\n",
    "\n",
    "# --- 1. Create a Sample DataFrame ---\n",
    "print(\"--- Creating Sample DataFrame ---\")\n",
    "data = {\n",
    "    'ProductID': [101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n",
    "    'ProductName': ['Laptop', 'Keyboard', 'Mouse', 'Monitor', 'Webcam', 'Printer', 'Speaker', 'Headphones', 'Microphone', 'Router'],\n",
    "    'Category': ['Electronics', 'Electronics', 'Electronics', 'Electronics', 'Electronics', 'Electronics', 'Audio', np.nan, 'Audio', 'Network'], # Missing value\n",
    "    'Price': [1200.50, 75.00, 25.99, 300.00, -50.00, 250.00, 150.00, 99.50, 70.00, 80.00], # Negative price\n",
    "    'StockQuantity': [10, 50, 0, 15, 25, 5, 12, 30, 8, 20],\n",
    "    'ReleaseDate': ['2023-01-10', '2023-01-11', '2023-01-11', '2023-01-12', '2023-01-12', '2023-01-13', '2023-01-13', '2023-01-14', '2023-01-14', 'InvalidDate'], # Invalid date format\n",
    "    'IsActive': [True, False, True, True, False, True, True, False, True, True]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- 2. Define Validation Functions ---\n",
    "\n",
    "def check_missing_values(df, column_name, is_required=True):\n",
    "    \"\"\"Checks for missing values in a specified column.\"\"\"\n",
    "    if is_required and df[column_name].isnull().any():\n",
    "        null_count = df[column_name].isnull().sum()\n",
    "        return f\"Column '{column_name}': Contains {null_count} missing values, but is required.\"\n",
    "    elif df[column_name].isnull().any() and not is_required:\n",
    "         # Optional columns can have missing values, maybe just report count\n",
    "         # null_count = df[column_name].isnull().sum()\n",
    "         # return f\"Column '{column_name}': Contains {null_count} missing values (optional column).\"\n",
    "         pass # No violation if not required\n",
    "    return None\n",
    "\n",
    "def check_data_type(df, column_name, expected_dtype):\n",
    "    \"\"\"Checks if a column's data type matches the expected type.\"\"\"\n",
    "    # Pandas dtypes can be tricky, especially with NaNs.\n",
    "    # This is a basic check. More robust checks might involve type casting.\n",
    "    if df[column_name].dtype != expected_dtype:\n",
    "        # Allow numeric types to be checked against compatible numeric dtypes\n",
    "        if not (pd.api.types.is_numeric_dtype(df[column_name].dtype) and pd.api.types.is_numeric_dtype(expected_dtype)):\n",
    "             return f\"Column '{column_name}': Incorrect data type. Expected '{expected_dtype}', got '{df[column_name].dtype}'.\"\n",
    "    return None\n",
    "\n",
    "def check_value_range(df, column_name, min_value=None, max_value=None):\n",
    "    \"\"\"Checks if values in a numerical column are within a specified range.\"\"\"\n",
    "    if not pd.api.types.is_numeric_dtype(df[column_name].dtype):\n",
    "        return f\"Column '{column_name}': Cannot perform range check on non-numeric type '{df[column_name].dtype}'.\"\n",
    "\n",
    "    violations = []\n",
    "    if min_value is not None:\n",
    "        # Check for values below the minimum, ignoring NaNs\n",
    "        if (df[column_name].dropna() < min_value).any():\n",
    "            invalid_count = (df[column_name].dropna() < min_value).sum()\n",
    "            violations.append(f\"Contains {invalid_count} values below the minimum ({min_value}).\")\n",
    "\n",
    "    if max_value is not None:\n",
    "         # Check for values above the maximum, ignoring NaNs\n",
    "         if (df[column_name].dropna() > max_value).any():\n",
    "             invalid_count = (df[column_name].dropna() > max_value).sum()\n",
    "             violations.append(f\"Contains {invalid_count} values above the maximum ({max_value}).\")\n",
    "\n",
    "    if violations:\n",
    "        return f\"Column '{column_name}': Value range violations: {', '.join(violations)}\"\n",
    "    return None\n",
    "\n",
    "def check_allowed_values(df, column_name, allowed_list):\n",
    "    \"\"\"Checks if values in a column are within a list of allowed values.\"\"\"\n",
    "    # Check if non-null unique values are in the allowed list\n",
    "    invalid_values = df[column_name].dropna()[~df[column_name].dropna().isin(allowed_list)].unique()\n",
    "    if invalid_values.size > 0:\n",
    "        return f\"Column '{column_name}': Contains invalid values: {list(invalid_values)}\"\n",
    "    return None\n",
    "\n",
    "# --- 3. Apply Validation ---\n",
    "print(\"--- Applying Validation Checks ---\")\n",
    "\n",
    "validation_issues = []\n",
    "\n",
    "# Define checks to apply\n",
    "# Format: (check_function, column_name, *args)\n",
    "checks_to_run = [\n",
    "    (check_missing_values, 'ProductID', True), # ProductID required\n",
    "    (check_data_type, 'ProductID', 'int64'),\n",
    "    (check_missing_values, 'ProductName', True), # ProductName required\n",
    "    (check_data_type, 'ProductName', 'object'),\n",
    "    (check_missing_values, 'Category', True), # Category required\n",
    "    (check_data_type, 'Category', 'object'),\n",
    "    (check_missing_values, 'Price', True), # Price required\n",
    "    (check_data_type, 'Price', 'float64'),\n",
    "    (check_value_range, 'Price', 0.0, None), # Price must be >= 0\n",
    "    (check_missing_values, 'StockQuantity', True), # StockQuantity required\n",
    "    (check_data_type, 'StockQuantity', 'int64'),\n",
    "    (check_value_range, 'StockQuantity', 0, None), # StockQuantity must be >= 0\n",
    "    (check_missing_values, 'ReleaseDate', True), # ReleaseDate required\n",
    "    (check_data_type, 'ReleaseDate', 'object'), # Basic type check, format check below\n",
    "    # Note: Date format validation requires more specific logic (e.g., using pd.to_datetime with format)\n",
    "    # Example (conceptual):\n",
    "    # (check_date_format, 'ReleaseDate', '%Y-%m-%d'),\n",
    "    (check_missing_values, 'IsActive', True), # IsActive required\n",
    "    (check_data_type, 'IsActive', 'bool'),\n",
    "    (check_allowed_values, 'Category', ['Electronics', 'Audio', 'Accessories', 'Software', 'Network']), # Allowed categories\n",
    "]\n",
    "\n",
    "# Run checks\n",
    "for check_func, col_name, *args in checks_to_run:\n",
    "    # Ensure column exists before checking\n",
    "    if col_name not in df.columns:\n",
    "        if args and args[0] is True: # Check if it was a required column check\n",
    "             validation_issues.append(f\"Required Column Missing: Column '{col_name}' is defined in checks but not found in DataFrame.\")\n",
    "        continue # Skip checks for non-existent columns\n",
    "\n",
    "    issue = check_func(df, col_name, *args)\n",
    "    if issue:\n",
    "        validation_issues.append(issue)\n",
    "\n",
    "# --- 4. Report Validation Results ---\n",
    "print(\"--- Data Validation Report ---\")\n",
    "\n",
    "if not validation_issues:\n",
    "    print(\"Validation Successful: No issues found based on defined checks.\")\n",
    "else:\n",
    "    print(\"Validation Failed: The following data quality issues were detected:\")\n",
    "    for issue in validation_issues:\n",
    "        print(f\"- {issue}\")\n",
    "\n",
    "# --- Conclusion ---\n",
    "# This script provides a basic framework for automated data validation\n",
    "# using pandas. You can extend this by adding more validation functions\n",
    "# and defining comprehensive checks_to_run for your specific dataset.\n",
    "# For more complex scenarios, dedicated data validation libraries are recommended.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
