{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Handling Schema Mismatches using Spark\n",
    "**Description**: Use Apache Spark to address schema mismatches by transforming data to match\n",
    "the expected schema.\n",
    "\n",
    "**Steps**:\n",
    "1. Create Spark session\n",
    "2. Load dataframe\n",
    "3. Define the expected schema\n",
    "4. Handle schema mismatches\n",
    "5. Show corrected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StructType, StructField, StringType, IntegerType\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Step 1: Create Spark session\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# Step 1: Create Spark session\n",
    "spark = SparkSession.builder.appName(\"SchemaMismatchHandling\").getOrCreate()\n",
    "\n",
    "# Step 2: Load dataframe (example data)\n",
    "data = [(\"Alice\", 25), (\"Bob\", None), (\"Charlie\", 35)]\n",
    "columns = [\"Name\", \"Age\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Step 3: Define the expected schema\n",
    "expected_schema = StructType([\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Age\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Step 4: Handle schema mismatches\n",
    "df_corrected = spark.createDataFrame(df.rdd, schema=expected_schema)\n",
    "\n",
    "# Step 5: Show corrected data\n",
    "df_corrected.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Detect and Correct Incomplete Data in ETL\n",
    "**Description**: Use Python and Pandas to detect incomplete data in an ETL process and fill\n",
    "missing values with estimates.\n",
    "\n",
    "**Steps**:\n",
    "1. Detect incomplete data\n",
    "2. Fill missing values\n",
    "3. Report changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incomplete Data:\n",
      "      Name   Age Gender\n",
      "1      Bob   NaN      M\n",
      "2  Charlie  35.0   None\n",
      "\n",
      "Data after filling missing values:\n",
      "      Name   Age   Gender\n",
      "0    Alice  25.0        F\n",
      "1      Bob  30.0        M\n",
      "2  Charlie  35.0  Unknown\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example data for ETL process\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [25, None, 35], 'Gender': ['F', 'M', None]}\n",
    "df_etl = pd.DataFrame(data)\n",
    "\n",
    "# Step 1: Detect incomplete data\n",
    "incomplete_data = df_etl[df_etl.isnull().any(axis=1)]\n",
    "print(\"Incomplete Data:\")\n",
    "print(incomplete_data)\n",
    "\n",
    "# Step 2: Fill missing values\n",
    "df_filled = df_etl.fillna({'Age': df_etl['Age'].mean(), 'Gender': 'Unknown'})\n",
    "\n",
    "# Step 3: Report changes\n",
    "print(\"\\nData after filling missing values:\")\n",
    "print(df_filled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
