{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating a dummy CSV file ---\n",
      "Dummy CSV file 'dummy_data_with_missing.csv' created.\n",
      "-------------------------\n",
      "\n",
      "--- Step 1: Load the data from CSV ---\n",
      "Successfully loaded 'dummy_data_with_missing.csv' into a DataFrame.\n",
      "DataFrame Head:\n",
      "   ColumnA ColumnB  ColumnC ColumnD\n",
      "0      1.0       A     10.1    True\n",
      "1      2.0       B     20.2   False\n",
      "2      3.0       C      NaN    True\n",
      "3      NaN       D     40.4    True\n",
      "4      5.0       E     50.5   False\n",
      "\n",
      "\n",
      "--- Step 2: Check for missing values using isnull() ---\n",
      "Boolean DataFrame indicating missing values:\n",
      "   ColumnA  ColumnB  ColumnC  ColumnD\n",
      "0    False    False    False    False\n",
      "1    False    False    False    False\n",
      "2    False    False     True    False\n",
      "3     True    False    False    False\n",
      "4    False    False    False    False\n",
      "5    False    False    False     True\n",
      "6     True    False    False    False\n",
      "7    False    False    False    False\n",
      "8    False    False     True    False\n",
      "9    False    False     True    False\n",
      "\n",
      "\n",
      "--- Step 3: Summarize missing data using sum() ---\n",
      "Count of missing values per column:\n",
      "ColumnA    2\n",
      "ColumnB    0\n",
      "ColumnC    3\n",
      "ColumnD    1\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Total number of missing values in the DataFrame: 6\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question: Introduction to Missing Data in a DataFrame\n",
    "# Description: Load a simple CSV file into a DataFrame and identify missing values.\n",
    "\n",
    "# Steps to follow:\n",
    "# 1. Load the data: Use the pandas library to read a CSV file.\n",
    "# 2. Check for missing values: Use the isnull() method to find missing values.\n",
    "# 3. Summarize missing data: Use the sum() function to count the number of missing values in each column.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- Introduction ---\n",
    "# This script demonstrates how to load a CSV file into a pandas DataFrame\n",
    "# and identify/summarize missing values, following the provided steps.\n",
    "\n",
    "# --- Create a dummy CSV file for demonstration ---\n",
    "# In a real scenario, you would replace this section with loading your actual CSV.\n",
    "print(\"--- Creating a dummy CSV file ---\")\n",
    "dummy_csv_data = {\n",
    "    'ColumnA': [1, 2, 3, np.nan, 5, 6, np.nan, 8, 9, 10],\n",
    "    'ColumnB': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],\n",
    "    'ColumnC': [10.1, 20.2, np.nan, 40.4, 50.5, 60.6, 70.7, 80.8, np.nan, np.nan],\n",
    "    'ColumnD': [True, False, True, True, False, np.nan, True, False, True, False]\n",
    "}\n",
    "dummy_df = pd.DataFrame(dummy_csv_data)\n",
    "\n",
    "csv_filename = 'dummy_data_with_missing.csv'\n",
    "dummy_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"Dummy CSV file '{csv_filename}' created.\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# --- Steps to follow: ---\n",
    "\n",
    "# 1. Load the data: Use the pandas library to read a CSV file.\n",
    "print(\"\\n--- Step 1: Load the data from CSV ---\")\n",
    "try:\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    print(f\"Successfully loaded '{csv_filename}' into a DataFrame.\")\n",
    "    print(\"DataFrame Head:\")\n",
    "    print(df.head())\n",
    "    print(\"\\n\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{csv_filename}' was not found.\")\n",
    "    # Exit or handle the error appropriately in a real script\n",
    "    exit()\n",
    "\n",
    "\n",
    "# 2. Check for missing values: Use the isnull() method to find missing values.\n",
    "print(\"--- Step 2: Check for missing values using isnull() ---\")\n",
    "# isnull() returns a DataFrame of the same shape as the original,\n",
    "# with True where data is missing (NaN, None) and False otherwise.\n",
    "missing_values_bool_df = df.isnull()\n",
    "\n",
    "print(\"Boolean DataFrame indicating missing values:\")\n",
    "print(missing_values_bool_df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 3. Summarize missing data: Use the sum() function to count the number of missing values in each column.\n",
    "print(\"--- Step 3: Summarize missing data using sum() ---\")\n",
    "# Applying sum() to the boolean DataFrame from isnull() counts the True values in each column.\n",
    "missing_values_count = df.isnull().sum()\n",
    "\n",
    "print(\"Count of missing values per column:\")\n",
    "print(missing_values_count)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Optional: Check total missing values in the entire DataFrame\n",
    "total_missing = missing_values_count.sum()\n",
    "print(f\"Total number of missing values in the DataFrame: {total_missing}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Clean up the dummy CSV file ---\n",
    "# In a real script, you might not need to remove the file immediately.\n",
    "# os.remove(csv_filename)\n",
    "# print(f\"Dummy CSV file '{csv_filename}' removed.\")\n",
    "\n",
    "# --- Conclusion ---\n",
    "# The script demonstrated loading a CSV, identifying missing values\n",
    "# using isnull(), and summarizing them per column using sum().\n",
    "# This is the first step in understanding the completeness of your dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating a dummy CSV file ---\n",
      "Dummy CSV file 'dummy_data_for_dropping.csv' created for this demonstration.\n",
      "-------------------------\n",
      "\n",
      "--- Loading the data from CSV ---\n",
      "Successfully loaded 'dummy_data_for_dropping.csv' into a DataFrame.\n",
      "Original DataFrame:\n",
      "   ColumnA ColumnB  ColumnC ColumnD\n",
      "0      1.0       A     10.1    True\n",
      "1      2.0       B     20.2   False\n",
      "2      3.0       C      NaN    True\n",
      "3      NaN       D     40.4    True\n",
      "4      5.0       E     50.5   False\n",
      "5      6.0       F     60.6     NaN\n",
      "6      NaN       G     70.7    True\n",
      "7      8.0       H     80.8   False\n",
      "8      9.0       I      NaN    True\n",
      "9     10.0       J      NaN   False\n",
      "\n",
      "\n",
      "Initial count of missing values per column:\n",
      "ColumnA    2\n",
      "ColumnB    0\n",
      "ColumnC    3\n",
      "ColumnD    1\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "--- Step 1: Use dropna() method to remove rows with missing values ---\n",
      "DataFrame after dropping rows with any missing values:\n",
      "   ColumnA ColumnB  ColumnC ColumnD\n",
      "0      1.0       A     10.1    True\n",
      "1      2.0       B     20.2   False\n",
      "4      5.0       E     50.5   False\n",
      "7      8.0       H     80.8   False\n",
      "\n",
      "\n",
      "Original number of rows: 10\n",
      "Number of rows after dropping: 4\n",
      "\n",
      "\n",
      "Count of missing values per column in the cleaned DataFrame:\n",
      "ColumnA    0\n",
      "ColumnB    0\n",
      "ColumnC    0\n",
      "ColumnD    0\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question: Dropping Rows with Missing Values\n",
    "# Description: Practice the deletion method by removing rows with any missing values from a dataset.\n",
    "\n",
    "# Steps to follow:\n",
    "# 1. Use dropna() method: Use the dropna() method to remove rows with missing values.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- Introduction ---\n",
    "# This script demonstrates how to remove rows with missing values\n",
    "# from a pandas DataFrame using the dropna() method, following the provided step.\n",
    "\n",
    "# --- Create a dummy CSV file for demonstration ---\n",
    "# This is the same dummy data used in the 'intro_missing_data' example.\n",
    "print(\"--- Creating a dummy CSV file ---\")\n",
    "dummy_csv_data = {\n",
    "    'ColumnA': [1, 2, 3, np.nan, 5, 6, np.nan, 8, 9, 10],\n",
    "    'ColumnB': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],\n",
    "    'ColumnC': [10.1, 20.2, np.nan, 40.4, 50.5, 60.6, 70.7, 80.8, np.nan, np.nan],\n",
    "    'ColumnD': [True, False, True, True, False, np.nan, True, False, True, False]\n",
    "}\n",
    "dummy_df = pd.DataFrame(dummy_csv_data)\n",
    "\n",
    "csv_filename = 'dummy_data_for_dropping.csv' # Use a different filename to avoid conflict\n",
    "dummy_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"Dummy CSV file '{csv_filename}' created for this demonstration.\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# --- Load the data ---\n",
    "# Load the dummy CSV file into a DataFrame\n",
    "print(\"\\n--- Loading the data from CSV ---\")\n",
    "try:\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    print(f\"Successfully loaded '{csv_filename}' into a DataFrame.\")\n",
    "    print(\"Original DataFrame:\")\n",
    "    print(df)\n",
    "    print(\"\\n\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{csv_filename}' was not found.\")\n",
    "    # Exit or handle the error appropriately\n",
    "    exit()\n",
    "\n",
    "# Check initial missing values\n",
    "print(\"Initial count of missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Steps to follow: ---\n",
    "\n",
    "# 1. Use dropna() method: Use the dropna() method to remove rows with missing values.\n",
    "print(\"--- Step 1: Use dropna() method to remove rows with missing values ---\")\n",
    "\n",
    "# The dropna() method by default removes rows (axis=0) that contain *any* missing values (how='any').\n",
    "# It returns a new DataFrame with the rows dropped. The original DataFrame is not modified unless inplace=True is used.\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "print(\"DataFrame after dropping rows with any missing values:\")\n",
    "print(df_cleaned)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Verify the number of rows after dropping\n",
    "print(f\"Original number of rows: {len(df)}\")\n",
    "print(f\"Number of rows after dropping: {len(df_cleaned)}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Verify missing values in the cleaned DataFrame\n",
    "print(\"Count of missing values per column in the cleaned DataFrame:\")\n",
    "print(df_cleaned.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# --- Clean up the dummy CSV file ---\n",
    "# os.remove(csv_filename)\n",
    "# print(f\"Dummy CSV file '{csv_filename}' removed.\")\n",
    "\n",
    "# --- Conclusion ---\n",
    "# The script successfully demonstrated how to use the dropna() method\n",
    "# to remove rows containing any missing values from the DataFrame.\n",
    "# This is one way to handle missing data, but it can lead to significant\n",
    "# data loss if many rows have missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating a dummy CSV file ---\n",
      "Dummy CSV file 'dummy_data_for_dropping_cols.csv' created for this demonstration.\n",
      "-------------------------\n",
      "\n",
      "--- Loading the data from CSV ---\n",
      "Successfully loaded 'dummy_data_for_dropping_cols.csv' into a DataFrame.\n",
      "Original DataFrame:\n",
      "   ColumnA ColumnB  ColumnC_with_NaNs ColumnD_with_NaNs  ColumnE_no_NaNs\n",
      "0        1       A               10.1              True              100\n",
      "1        2       B               20.2             False              200\n",
      "2        3       C                NaN              True              300\n",
      "3        4       D               40.4              True              400\n",
      "4        5       E               50.5             False              500\n",
      "5        6       F               60.6               NaN              600\n",
      "6        7       G               70.7              True              700\n",
      "7        8       H               80.8             False              800\n",
      "8        9       I                NaN              True              900\n",
      "9       10       J                NaN             False             1000\n",
      "\n",
      "\n",
      "Initial count of missing values per column:\n",
      "ColumnA              0\n",
      "ColumnB              0\n",
      "ColumnC_with_NaNs    3\n",
      "ColumnD_with_NaNs    1\n",
      "ColumnE_no_NaNs      0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "--- Step 1: Use dropna(axis=1) to remove columns with missing values ---\n",
      "DataFrame after dropping columns with any missing values:\n",
      "   ColumnA ColumnB  ColumnE_no_NaNs\n",
      "0        1       A              100\n",
      "1        2       B              200\n",
      "2        3       C              300\n",
      "3        4       D              400\n",
      "4        5       E              500\n",
      "5        6       F              600\n",
      "6        7       G              700\n",
      "7        8       H              800\n",
      "8        9       I              900\n",
      "9       10       J             1000\n",
      "\n",
      "\n",
      "Original columns: ['ColumnA', 'ColumnB', 'ColumnC_with_NaNs', 'ColumnD_with_NaNs', 'ColumnE_no_NaNs']\n",
      "Columns after dropping: ['ColumnA', 'ColumnB', 'ColumnE_no_NaNs']\n",
      "\n",
      "\n",
      "Count of missing values per column in the cleaned DataFrame:\n",
      "ColumnA            0\n",
      "ColumnB            0\n",
      "ColumnE_no_NaNs    0\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question: Dropping Columns with Missing Values\n",
    "# Description: Practice deleting entire columns that contain missing values.\n",
    "\n",
    "# Steps to follow:\n",
    "# 1. Use dropna() with axis parameter: Set axis=1 in dropna() to remove columns with missing values.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- Introduction ---\n",
    "# This script demonstrates how to remove columns with missing values\n",
    "# from a pandas DataFrame using the dropna() method with axis=1,\n",
    "# following the provided step.\n",
    "\n",
    "# --- Create a dummy CSV file for demonstration ---\n",
    "# We'll use a similar dummy dataset, ensuring some columns have NaNs.\n",
    "print(\"--- Creating a dummy CSV file ---\")\n",
    "dummy_csv_data = {\n",
    "    'ColumnA': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], # No missing values\n",
    "    'ColumnB': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'], # No missing values\n",
    "    'ColumnC_with_NaNs': [10.1, 20.2, np.nan, 40.4, 50.5, 60.6, 70.7, 80.8, np.nan, np.nan], # Has missing values\n",
    "    'ColumnD_with_NaNs': [True, False, True, True, False, np.nan, True, False, True, False], # Has missing values\n",
    "    'ColumnE_no_NaNs': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000] # No missing values\n",
    "}\n",
    "dummy_df = pd.DataFrame(dummy_csv_data)\n",
    "\n",
    "csv_filename = 'dummy_data_for_dropping_cols.csv' # Use a distinct filename\n",
    "dummy_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"Dummy CSV file '{csv_filename}' created for this demonstration.\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# --- Load the data ---\n",
    "# Load the dummy CSV file into a DataFrame\n",
    "print(\"\\n--- Loading the data from CSV ---\")\n",
    "try:\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    print(f\"Successfully loaded '{csv_filename}' into a DataFrame.\")\n",
    "    print(\"Original DataFrame:\")\n",
    "    print(df)\n",
    "    print(\"\\n\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{csv_filename}' was not found.\")\n",
    "    # Exit or handle the error appropriately\n",
    "    exit()\n",
    "\n",
    "# Check initial missing values count per column\n",
    "print(\"Initial count of missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Steps to follow: ---\n",
    "\n",
    "# 1. Use dropna() with axis parameter: Set axis=1 in dropna() to remove columns with missing values.\n",
    "print(\"--- Step 1: Use dropna(axis=1) to remove columns with missing values ---\")\n",
    "\n",
    "# The dropna() method with axis=1 removes columns.\n",
    "# By default, how='any' is used, meaning it removes columns that contain *any* missing values.\n",
    "# It returns a new DataFrame with the columns dropped. The original DataFrame is not modified unless inplace=True is used.\n",
    "df_cleaned_cols = df.dropna(axis=1)\n",
    "\n",
    "print(\"DataFrame after dropping columns with any missing values:\")\n",
    "print(df_cleaned_cols)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Verify the columns after dropping\n",
    "print(\"Original columns:\", df.columns.tolist())\n",
    "print(\"Columns after dropping:\", df_cleaned_cols.columns.tolist())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Verify missing values in the cleaned DataFrame (should be zero)\n",
    "print(\"Count of missing values per column in the cleaned DataFrame:\")\n",
    "print(df_cleaned_cols.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Clean up the dummy CSV file ---\n",
    "# os.remove(csv_filename)\n",
    "# print(f\"Dummy CSV file '{csv_filename}' removed.\")\n",
    "\n",
    "# --- Conclusion ---\n",
    "# The script successfully demonstrated how to use the dropna(axis=1) method\n",
    "# to remove columns containing any missing values from the DataFrame.\n",
    "# This method is useful when an entire column is sparse or irrelevant due to missing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Sample DataFrame ---\n",
      "Original DataFrame:\n",
      "   StudentID  ExamScore  HoursStudied  Passed\n",
      "0          1       85.0             5    True\n",
      "1          2       92.0             7    True\n",
      "2          3        NaN             6   False\n",
      "3          4       78.0             4    True\n",
      "4          5       95.0             8    True\n",
      "5          6       88.0             6    True\n",
      "6          7        NaN             5   False\n",
      "7          8       91.0             7    True\n",
      "8          9       80.0             4    True\n",
      "9         10       87.0             6    True\n",
      "\n",
      "\n",
      "Count of missing values in 'ExamScore' before imputation:\n",
      "2\n",
      "\n",
      "\n",
      "--- Step 1: Calculate mean and fill NA ---\n",
      "Calculated Mean of 'ExamScore': 87.00\n",
      "\n",
      "\n",
      "DataFrame after Mean Imputation on 'ExamScore':\n",
      "   StudentID  ExamScore  HoursStudied  Passed\n",
      "0          1       85.0             5    True\n",
      "1          2       92.0             7    True\n",
      "2          3       87.0             6   False\n",
      "3          4       78.0             4    True\n",
      "4          5       95.0             8    True\n",
      "5          6       88.0             6    True\n",
      "6          7       87.0             5   False\n",
      "7          8       91.0             7    True\n",
      "8          9       80.0             4    True\n",
      "9         10       87.0             6    True\n",
      "\n",
      "\n",
      "Count of missing values in 'ExamScore' after imputation:\n",
      "0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8807/3738137311.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['ExamScore'].fillna(mean_exam_score, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Question: Mean Imputation for Numerical Data\n",
    "# Description: Fill missing values in a numerical column with the mean of that column.\n",
    "\n",
    "# Steps to follow:\n",
    "# 1. Calculate mean and fill NA: Use mean() to calculate and fillna() to fill the missing values.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Introduction ---\n",
    "# This script demonstrates how to perform mean imputation, which involves\n",
    "# filling missing values in a numerical column with the mean of that column.\n",
    "# This is a common strategy for handling missing data.\n",
    "#\n",
    "# We will:\n",
    "# 1. Create a sample DataFrame with a numerical column containing missing values.\n",
    "# 2. Calculate the mean of the numerical column.\n",
    "# 3. Use the fillna() method to replace the missing values with the calculated mean.\n",
    "# 4. Show the DataFrame before and after the imputation.\n",
    "\n",
    "# --- 1. Create a Sample DataFrame ---\n",
    "print(\"--- Creating Sample DataFrame ---\")\n",
    "data = {\n",
    "    'StudentID': range(1, 11),\n",
    "    'ExamScore': [85, 92, np.nan, 78, 95, 88, np.nan, 91, 80, 87], # Introduce missing values (NaN)\n",
    "    'HoursStudied': [5, 7, 6, 4, 8, 6, 5, 7, 4, 6],\n",
    "    'Passed': [True, True, False, True, True, True, False, True, True, True]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Count of missing values in 'ExamScore' before imputation:\")\n",
    "print(df['ExamScore'].isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Steps to follow: ---\n",
    "\n",
    "# 1. Calculate mean and fill NA: Use mean() to calculate and fillna() to fill the missing values.\n",
    "print(\"--- Step 1: Calculate mean and fill NA ---\")\n",
    "\n",
    "# Calculate the mean of the 'ExamScore' column, ignoring NaN values by default\n",
    "mean_exam_score = df['ExamScore'].mean()\n",
    "\n",
    "print(f\"Calculated Mean of 'ExamScore': {mean_exam_score:.2f}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Fill the missing values (NaN) in the 'ExamScore' column with the calculated mean\n",
    "# Using inplace=True modifies the DataFrame directly\n",
    "df['ExamScore'].fillna(mean_exam_score, inplace=True)\n",
    "\n",
    "print(\"DataFrame after Mean Imputation on 'ExamScore':\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Verify that there are no more missing values in 'ExamScore'\n",
    "print(\"Count of missing values in 'ExamScore' after imputation:\")\n",
    "print(df['ExamScore'].isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Conclusion ---\n",
    "# The script successfully calculated the mean of the 'ExamScore' column\n",
    "# and used fillna() to replace the missing values with this mean.\n",
    "# Mean imputation is simple but can distort the distribution and reduce variance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Sample DataFrame ---\n",
      "Original DataFrame:\n",
      "   CustomerID ProductCategory  Rating  Purchased\n",
      "0           1     Electronics       4       True\n",
      "1           2        Clothing       5       True\n",
      "2           3             NaN       3      False\n",
      "3           4     Electronics       4       True\n",
      "4           5      Home Goods       5       True\n",
      "5           6        Clothing       4       True\n",
      "6           7             NaN       3      False\n",
      "7           8     Electronics       5       True\n",
      "8           9      Home Goods       4       True\n",
      "9          10        Clothing       4       True\n",
      "\n",
      "\n",
      "Count of missing values in 'ProductCategory' before imputation:\n",
      "2\n",
      "\n",
      "\n",
      "--- Step 1: Calculate mode and fill NA ---\n",
      "Calculated Mode of 'ProductCategory': 'Clothing'\n",
      "\n",
      "\n",
      "DataFrame after Mode Imputation on 'ProductCategory':\n",
      "   CustomerID ProductCategory  Rating  Purchased\n",
      "0           1     Electronics       4       True\n",
      "1           2        Clothing       5       True\n",
      "2           3        Clothing       3      False\n",
      "3           4     Electronics       4       True\n",
      "4           5      Home Goods       5       True\n",
      "5           6        Clothing       4       True\n",
      "6           7        Clothing       3      False\n",
      "7           8     Electronics       5       True\n",
      "8           9      Home Goods       4       True\n",
      "9          10        Clothing       4       True\n",
      "\n",
      "\n",
      "Count of missing values in 'ProductCategory' after imputation:\n",
      "0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8807/3560113477.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['ProductCategory'].fillna(mode_product_category, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Question: Mode Imputation for Categorical Data\n",
    "# Description: Fill missing values in a categorical column with the mode of that column.\n",
    "\n",
    "# Steps to follow:\n",
    "# 1. Calculate mode and fill NA: Use mode() to find the most frequent value and fillna() to fill the missing values.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Introduction ---\n",
    "# This script demonstrates how to perform mode imputation, which involves\n",
    "# filling missing values in a categorical column with the mode (most frequent value)\n",
    "# of that column. This is a common strategy for handling missing categorical data.\n",
    "#\n",
    "# We will:\n",
    "# 1. Create a sample DataFrame with a categorical column containing missing values.\n",
    "# 2. Calculate the mode of the categorical column.\n",
    "# 3. Use the fillna() method to replace the missing values with the calculated mode.\n",
    "# 4. Show the DataFrame before and after the imputation.\n",
    "\n",
    "# --- 1. Create a Sample DataFrame ---\n",
    "print(\"--- Creating Sample DataFrame ---\")\n",
    "data = {\n",
    "    'CustomerID': range(1, 11),\n",
    "    'ProductCategory': ['Electronics', 'Clothing', np.nan, 'Electronics', 'Home Goods', 'Clothing', np.nan, 'Electronics', 'Home Goods', 'Clothing'], # Introduce missing values (NaN)\n",
    "    'Rating': [4, 5, 3, 4, 5, 4, 3, 5, 4, 4],\n",
    "    'Purchased': [True, True, False, True, True, True, False, True, True, True]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Count of missing values in 'ProductCategory' before imputation:\")\n",
    "print(df['ProductCategory'].isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Steps to follow: ---\n",
    "\n",
    "# 1. Calculate mode and fill NA: Use mode() to find the most frequent value and fillna() to fill the missing values.\n",
    "print(\"--- Step 1: Calculate mode and fill NA ---\")\n",
    "\n",
    "# Calculate the mode of the 'ProductCategory' column.\n",
    "# .mode() can return multiple values if there's a tie. We usually take the first one [0].\n",
    "mode_product_category = df['ProductCategory'].mode()[0]\n",
    "\n",
    "print(f\"Calculated Mode of 'ProductCategory': '{mode_product_category}'\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Fill the missing values (NaN) in the 'ProductCategory' column with the calculated mode\n",
    "# Using inplace=True modifies the DataFrame directly\n",
    "df['ProductCategory'].fillna(mode_product_category, inplace=True)\n",
    "\n",
    "print(\"DataFrame after Mode Imputation on 'ProductCategory':\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Verify that there are no more missing values in 'ProductCategory'\n",
    "print(\"Count of missing values in 'ProductCategory' after imputation:\")\n",
    "print(df['ProductCategory'].isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Conclusion ---\n",
    "# The script successfully calculated the mode of the 'ProductCategory' column\n",
    "# and used fillna() to replace the missing values with this mode.\n",
    "# Mode imputation is a simple way to handle missing categorical data but\n",
    "# can potentially over-represent the most frequent category.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Sample DataFrame with Skewed Data ---\n",
      "Original DataFrame (first 10 rows):\n",
      "   PersonID  Income_USD  YearsExperience\n",
      "0         1   29.885438                4\n",
      "1         2   17.982311                6\n",
      "2         3   33.722013                8\n",
      "3         4         NaN                3\n",
      "4         5   16.654448               16\n",
      "5         6   16.654666                3\n",
      "6         7   71.049034               18\n",
      "7         8         NaN               14\n",
      "8         9   13.796577               18\n",
      "9        10   31.001886                2\n",
      "\n",
      "\n",
      "Count of missing values in 'Income_USD' before imputation:\n",
      "10\n",
      "\n",
      "\n",
      "--- Visualizing the Skewed Distribution (Original Data) ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Displaying Distribution Plot ---\n",
      "\n",
      "--- Step 1: Calculate median and fill NA ---\n",
      "Calculated Median of 'Income_USD': 18.15\n",
      "\n",
      "\n",
      "DataFrame after Median Imputation on 'Income_USD' (first 10 rows):\n",
      "   PersonID  Income_USD  YearsExperience\n",
      "0         1   29.885438                4\n",
      "1         2   17.982311                6\n",
      "2         3   33.722013                8\n",
      "3         4   18.146467                3\n",
      "4         5   16.654448               16\n",
      "5         6   16.654666                3\n",
      "6         7   71.049034               18\n",
      "7         8   18.146467               14\n",
      "8         9   13.796577               18\n",
      "9        10   31.001886                2\n",
      "\n",
      "\n",
      "Count of missing values in 'Income_USD' after imputation:\n",
      "0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8807/3252541480.py:77: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Income_USD'].fillna(median_income, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Question: Median Imputation for Skewed Data\n",
    "# Description: Handle missing values in columns with a skewed distribution using the median.\n",
    "\n",
    "# Steps to follow:\n",
    "# 1. Calculate median and fill NA: Use median() for skewed data and fillna() to handle missing values.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # Optional: for visualization\n",
    "\n",
    "# --- Introduction ---\n",
    "# This script demonstrates how to perform median imputation, which is\n",
    "# often preferred over mean imputation for numerical columns with\n",
    "# skewed distributions. The median is less sensitive to extreme values (outliers)\n",
    "# that can disproportionately affect the mean in skewed data.\n",
    "#\n",
    "# We will:\n",
    "# 1. Create a sample DataFrame with a numerical column having a skewed distribution and missing values.\n",
    "# 2. (Optional) Visualize the skewed distribution.\n",
    "# 3. Calculate the median of the numerical column.\n",
    "# 4. Use the fillna() method to replace the missing values with the calculated median.\n",
    "# 5. Show the DataFrame before and after the imputation.\n",
    "\n",
    "# --- 1. Create a Sample DataFrame with Skewed Data ---\n",
    "print(\"--- Creating Sample DataFrame with Skewed Data ---\")\n",
    "# Simulate a right-skewed distribution (e.g., income, house prices)\n",
    "# Let's use a log-normal distribution or add some high values to a normal distribution\n",
    "np.random.seed(42) # for reproducibility\n",
    "\n",
    "# Option A: Using log-normal distribution (naturally skewed)\n",
    "skewed_data = np.random.lognormal(mean=3, sigma=0.8, size=100)\n",
    "\n",
    "# Introduce some missing values\n",
    "missing_indices = np.random.choice(len(skewed_data), size=10, replace=False)\n",
    "skewed_data[missing_indices] = np.nan\n",
    "\n",
    "data = {\n",
    "    'PersonID': range(1, 101),\n",
    "    'Income_USD': skewed_data,\n",
    "    'YearsExperience': np.random.randint(1, 20, size=100) # Another column\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame (first 10 rows):\")\n",
    "print(df.head(10))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Count of missing values in 'Income_USD' before imputation:\")\n",
    "print(df['Income_USD'].isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- 2. (Optional) Visualize the Skewed Distribution ---\n",
    "print(\"--- Visualizing the Skewed Distribution (Original Data) ---\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "# Drop NaNs for plotting the distribution shape\n",
    "plt.hist(df['Income_USD'].dropna(), bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.title(\"Distribution of Original 'Income_USD'\")\n",
    "plt.xlabel(\"Income (USD)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "print(\"--- Displaying Distribution Plot ---\\n\")\n",
    "\n",
    "\n",
    "# --- Steps to follow: ---\n",
    "\n",
    "# 1. Calculate median and fill NA: Use median() for skewed data and fillna() to handle missing values.\n",
    "print(\"--- Step 1: Calculate median and fill NA ---\")\n",
    "\n",
    "# Calculate the median of the 'Income_USD' column, ignoring NaN values by default\n",
    "median_income = df['Income_USD'].median()\n",
    "\n",
    "print(f\"Calculated Median of 'Income_USD': {median_income:.2f}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Fill the missing values (NaN) in the 'Income_USD' column with the calculated median\n",
    "# Using inplace=True modifies the DataFrame directly\n",
    "df['Income_USD'].fillna(median_income, inplace=True)\n",
    "\n",
    "print(\"DataFrame after Median Imputation on 'Income_USD' (first 10 rows):\")\n",
    "print(df.head(10))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Verify that there are no more missing values in 'Income_USD'\n",
    "print(\"Count of missing values in 'Income_USD' after imputation:\")\n",
    "print(df['Income_USD'].isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Conclusion ---\n",
    "# The script successfully calculated the median of the skewed 'Income_USD' column\n",
    "# and used fillna() to replace the missing values with this median.\n",
    "# Median imputation is a robust strategy for skewed data as it is less affected\n",
    "# by extreme values compared to mean imputation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Sample DataFrame ---\n",
      "Original DataFrame:\n",
      "   Feature1  Feature2  Feature3 Feature4\n",
      "0       1.1     11.11     101.0     True\n",
      "1       2.2     12.12       NaN    False\n",
      "2       NaN     13.13     103.0     True\n",
      "3       4.4       NaN     104.0    False\n",
      "4       5.5     15.15     105.0     True\n",
      "5       6.6     16.16       NaN    False\n",
      "6       NaN     17.17     107.0     True\n",
      "7       8.8       NaN     108.0    False\n",
      "8       9.9     19.19     109.0     True\n",
      "9      10.1     20.20     110.0      NaN\n",
      "\n",
      "\n",
      "Count of missing values before imputation:\n",
      "Feature1    2\n",
      "Feature2    2\n",
      "Feature3    2\n",
      "Feature4    1\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "--- Step 2: Use KNNImputer to fill in missing values ---\n",
      "DataFrame after KNN Imputation:\n",
      "   Feature1  Feature2  Feature3 Feature4\n",
      "0      1.10    11.110     101.0     True\n",
      "1      2.20    12.120     104.0    False\n",
      "2      3.96    13.130     103.0     True\n",
      "3      4.40    14.746     104.0    False\n",
      "4      5.50    15.150     105.0     True\n",
      "5      6.60    16.160     105.4    False\n",
      "6      7.04    17.170     107.0     True\n",
      "7      8.80    17.574     108.0    False\n",
      "8      9.90    19.190     109.0     True\n",
      "9     10.10    20.200     110.0      NaN\n",
      "\n",
      "\n",
      "Count of missing values after imputation:\n",
      "Feature1    0\n",
      "Feature2    0\n",
      "Feature3    0\n",
      "Feature4    1\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question: KNN Imputation\n",
    "# Description: Use K-Nearest Neighbors to impute missing values in a dataset.\n",
    "\n",
    "# Steps to follow:\n",
    "# 1. Install and import required libraries: Use pip install sklearn if not already installed.\n",
    "# 2. KNN Imputer: Use KNNImputer to fill in missing values.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer # Import the KNNImputer\n",
    "\n",
    "# --- Introduction ---\n",
    "# This script demonstrates how to use the K-Nearest Neighbors (KNN) algorithm\n",
    "# to impute (fill in) missing values in a numerical dataset.\n",
    "# KNN imputation estimates missing values based on the values of the 'k'\n",
    "# nearest data points in the feature space.\n",
    "#\n",
    "# We will:\n",
    "# 1. Create a sample DataFrame with numerical columns containing missing values.\n",
    "# 2. Use the KNNImputer from scikit-learn to fill in the missing values.\n",
    "# 3. Show the DataFrame before and after imputation.\n",
    "\n",
    "# --- 1. Create a Sample DataFrame ---\n",
    "print(\"--- Creating Sample DataFrame ---\")\n",
    "# Create a DataFrame with multiple numerical columns and missing values\n",
    "data = {\n",
    "    'Feature1': [1.1, 2.2, np.nan, 4.4, 5.5, 6.6, np.nan, 8.8, 9.9, 10.10],\n",
    "    'Feature2': [11.11, 12.12, 13.13, np.nan, 15.15, 16.16, 17.17, np.nan, 19.19, 20.20],\n",
    "    'Feature3': [101, np.nan, 103, 104, 105, np.nan, 107, 108, 109, 110],\n",
    "    'Feature4': [True, False, True, False, True, False, True, False, True, np.nan] # Include a non-numeric column to show it's excluded\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Count of missing values before imputation:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Steps to follow: ---\n",
    "\n",
    "# 1. Install and import required libraries: Use pip install sklearn if not already installed.\n",
    "# (Imported at the top. Installation is done via pip in your environment)\n",
    "\n",
    "# 2. KNN Imputer: Use KNNImputer to fill in missing values.\n",
    "print(\"--- Step 2: Use KNNImputer to fill in missing values ---\")\n",
    "\n",
    "# Select only numerical columns for KNN imputation, as it works on numerical data\n",
    "numerical_df = df.select_dtypes(include=np.number)\n",
    "\n",
    "# Initialize the KNNImputer\n",
    "# n_neighbors: The number of neighbors to consider for imputation. Common values are 3, 5, 7.\n",
    "# weights: 'uniform' (all neighbors weighted equally) or 'distance' (closer neighbors have more weight).\n",
    "# metric: Distance metric to use (e.g., 'nan_ euclidean').\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Apply the imputer to the numerical data\n",
    "# The imputer returns a numpy array\n",
    "imputed_data = imputer.fit_transform(numerical_df)\n",
    "\n",
    "# Convert the imputed numpy array back to a pandas DataFrame\n",
    "# Use the original numerical column names and index\n",
    "imputed_df = pd.DataFrame(imputed_data, columns=numerical_df.columns, index=numerical_df.index)\n",
    "\n",
    "# Optionally, merge the imputed numerical columns back with the non-numerical columns\n",
    "# In this example, 'Feature4' was excluded.\n",
    "# Identify non-numerical columns\n",
    "non_numerical_cols = df.select_dtypes(exclude=np.number).columns\n",
    "df_cleaned = imputed_df.copy()\n",
    "for col in non_numerical_cols:\n",
    "    df_cleaned[col] = df[col]\n",
    "\n",
    "# Reorder columns to match the original DataFrame if desired\n",
    "df_cleaned = df_cleaned[df.columns]\n",
    "\n",
    "\n",
    "print(\"DataFrame after KNN Imputation:\")\n",
    "print(df_cleaned)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Count of missing values after imputation:\")\n",
    "print(df_cleaned.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# --- Conclusion ---\n",
    "# The script successfully used KNNImputer to estimate and fill the missing\n",
    "# numerical values based on the values of their 5 nearest neighbors.\n",
    "# KNN imputation can be more accurate than simple mean/median imputation\n",
    "# but can be computationally more expensive, especially for large datasets\n",
    "# or a large number of features. It also requires all features to be numerical\n",
    "# for distance calculation (or requires appropriate encoding/handling of\n",
    "# categorical features before imputation).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Sample DataFrame ---\n",
      "Original DataFrame:\n",
      "   OrderID ShippingMethod Region  Amount\n",
      "0        1       Standard  North     100\n",
      "1        2        Express  South     250\n",
      "2        3            NaN   East      50\n",
      "3        4       Standard   West     120\n",
      "4        5        Express  North     300\n",
      "5        6       Standard  South      90\n",
      "6        7            NaN   East      60\n",
      "7        8       Standard   West     150\n",
      "8        9        Express  North     280\n",
      "9       10       Standard  South     110\n",
      "\n",
      "\n",
      "--- Step 1: Identify missing values in 'ShippingMethod' ---\n",
      "Boolean Series indicating missing values in 'ShippingMethod':\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4    False\n",
      "5    False\n",
      "6     True\n",
      "7    False\n",
      "8    False\n",
      "9    False\n",
      "Name: ShippingMethod, dtype: bool\n",
      "\n",
      "\n",
      "Count of missing values in 'ShippingMethod' before imputation:\n",
      "2\n",
      "\n",
      "\n",
      "--- Step 2: Impute with next frequent category ---\n",
      "Frequency counts for 'ShippingMethod':\n",
      "ShippingMethod\n",
      "Standard    5\n",
      "Express     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Most frequent category (Mode): Standard\n",
      "Next most frequent category: Express\n",
      "Filling missing values in 'ShippingMethod' with 'Express'...\n",
      "\n",
      "DataFrame after Imputation on 'ShippingMethod':\n",
      "   OrderID ShippingMethod Region  Amount\n",
      "0        1       Standard  North     100\n",
      "1        2        Express  South     250\n",
      "2        3        Express   East      50\n",
      "3        4       Standard   West     120\n",
      "4        5        Express  North     300\n",
      "5        6       Standard  South      90\n",
      "6        7        Express   East      60\n",
      "7        8       Standard   West     150\n",
      "8        9        Express  North     280\n",
      "9       10       Standard  South     110\n",
      "\n",
      "\n",
      "Count of missing values in 'ShippingMethod' after imputation:\n",
      "0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8807/3003410401.py:75: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['ShippingMethod'].fillna(next_frequent_category, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Question: Detecting and Handling Missing Categorical Data\n",
    "# Description: Detect missing categorical data and handle it by filling with the next frequent category.\n",
    "\n",
    "# Steps to follow:\n",
    "# 1. Identify missing values in categorical data: Use the isnull() method on categorical columns.\n",
    "# 2. Impute with next frequent category: Use the mode() method to choose the next frequent category.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Introduction ---\n",
    "# This script demonstrates how to detect missing values in a categorical column\n",
    "# and handle them by filling with the *next* most frequent category.\n",
    "#\n",
    "# We will:\n",
    "# 1. Create a sample DataFrame with a categorical column containing missing values.\n",
    "# 2. Identify missing values using isnull().\n",
    "# 3. Calculate the frequency distribution to find the mode and the next frequent category.\n",
    "# 4. Impute the missing values with the next frequent category.\n",
    "# 5. Show the DataFrame before and after imputation.\n",
    "\n",
    "# --- 1. Create a Sample DataFrame ---\n",
    "print(\"--- Creating Sample DataFrame ---\")\n",
    "data = {\n",
    "    'OrderID': range(1, 11),\n",
    "    'ShippingMethod': ['Standard', 'Express', np.nan, 'Standard', 'Express', 'Standard', np.nan, 'Standard', 'Express', 'Standard'], # Introduce missing values\n",
    "    'Region': ['North', 'South', 'East', 'West', 'North', 'South', 'East', 'West', 'North', 'South'],\n",
    "    'Amount': [100, 250, 50, 120, 300, 90, 60, 150, 280, 110]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Steps to follow: ---\n",
    "\n",
    "# 1. Identify missing values in categorical data: Use the isnull() method on categorical columns.\n",
    "print(\"--- Step 1: Identify missing values in 'ShippingMethod' ---\")\n",
    "missing_shipping_method = df['ShippingMethod'].isnull()\n",
    "\n",
    "print(\"Boolean Series indicating missing values in 'ShippingMethod':\")\n",
    "print(missing_shipping_method)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Count of missing values in 'ShippingMethod' before imputation:\")\n",
    "print(df['ShippingMethod'].isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2. Impute with next frequent category: Use the mode() method to choose the next frequent category.\n",
    "print(\"--- Step 2: Impute with next frequent category ---\")\n",
    "\n",
    "# Calculate the frequency distribution\n",
    "frequency_counts = df['ShippingMethod'].value_counts()\n",
    "print(\"Frequency counts for 'ShippingMethod':\")\n",
    "print(frequency_counts)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Identify the mode (most frequent)\n",
    "mode_category = frequency_counts.index[0] if not frequency_counts.empty else None\n",
    "print(f\"Most frequent category (Mode): {mode_category}\")\n",
    "\n",
    "# Identify the next frequent category\n",
    "next_frequent_category = None\n",
    "if len(frequency_counts) > 1:\n",
    "    next_frequent_category = frequency_counts.index[1]\n",
    "    print(f\"Next most frequent category: {next_frequent_category}\")\n",
    "else:\n",
    "    print(\"There is no 'next' frequent category (only one or zero unique values).\")\n",
    "    print(\"Falling back to filling with the mode.\")\n",
    "    next_frequent_category = mode_category # Fallback\n",
    "\n",
    "# Fill the missing values (NaN) in the 'ShippingMethod' column with the next frequent category\n",
    "if next_frequent_category is not None:\n",
    "    print(f\"Filling missing values in 'ShippingMethod' with '{next_frequent_category}'...\")\n",
    "    df['ShippingMethod'].fillna(next_frequent_category, inplace=True)\n",
    "else:\n",
    "    print(\"Cannot fill missing values as no category could be determined.\")\n",
    "\n",
    "\n",
    "print(\"\\nDataFrame after Imputation on 'ShippingMethod':\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Verify that there are no more missing values in 'ShippingMethod'\n",
    "print(\"Count of missing values in 'ShippingMethod' after imputation:\")\n",
    "print(df['ShippingMethod'].isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Conclusion ---\n",
    "# The script successfully identified missing categorical data, calculated\n",
    "# the frequency distribution, determined the next most frequent category,\n",
    "# and used fillna() to replace the missing values with this category.\n",
    "# This method is useful when you want to avoid over-representing the mode\n",
    "# but still use a data-driven approach for imputation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Sample DataFrame ---\n",
      "Original DataFrame:\n",
      "     Feature1   Feature2  Feature3  Feature_to_Impute\n",
      "0   37.454012  30.592645       7.0         168.906770\n",
      "1   95.071431   6.974693       8.0         149.464022\n",
      "2   73.199394  14.607232       3.0         107.938426\n",
      "3   59.865848  18.318092       1.0                NaN\n",
      "4   15.601864  22.803499       4.0         193.051061\n",
      "5   15.599452  39.258798       2.0         121.406850\n",
      "6    5.808361   9.983689       8.0          55.199836\n",
      "7   86.617615  25.711722       4.0          59.254701\n",
      "8   60.111501  29.620728       2.0          33.053388\n",
      "9   70.807258   2.322521       6.0           3.127281\n",
      "10   2.058449  30.377243       6.0                NaN\n",
      "11        NaN   8.526206       4.0          78.976304\n",
      "12  83.244264   3.252580       6.0          58.697635\n",
      "13  21.233911  47.444277       2.0           2.815965\n",
      "14  18.182497  48.281602       2.0                NaN\n",
      "15  18.340451  40.419867       4.0                NaN\n",
      "16        NaN  15.230688       8.0         158.035108\n",
      "17  52.475643   4.883606       NaN         121.191995\n",
      "18  43.194502  34.211651       9.0                NaN\n",
      "19  29.122914  22.007625       8.0         130.215405\n",
      "\n",
      "\n",
      "Count of missing values before imputation:\n",
      "Feature1             2\n",
      "Feature2             0\n",
      "Feature3             1\n",
      "Feature_to_Impute    5\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "--- Step 1: Partition the data based on missing values ---\n",
      "Data for training imputation model (non-missing target): 15 rows\n",
      "Data for predicting missing values (missing target): 5 rows\n",
      "\n",
      "\n",
      "--- Step 2: Train a regression model to predict missing values ---\n",
      "Imputation model (Linear Regression) trained successfully.\n",
      "\n",
      "\n",
      "--- Step 3: Impute missing values with predictions ---\n",
      "Predicted 5 missing values.\n",
      "\n",
      "\n",
      "DataFrame after Predictive Imputation:\n",
      "     Feature1   Feature2  Feature3  Feature_to_Impute\n",
      "0   37.454012  30.592645       7.0         168.906770\n",
      "1   95.071431   6.974693       8.0         149.464022\n",
      "2   73.199394  14.607232       3.0         107.938426\n",
      "3   59.865848  18.318092       1.0          46.284202\n",
      "4   15.601864  22.803499       4.0         193.051061\n",
      "5   15.599452  39.258798       2.0         121.406850\n",
      "6    5.808361   9.983689       8.0          55.199836\n",
      "7   86.617615  25.711722       4.0          59.254701\n",
      "8   60.111501  29.620728       2.0          33.053388\n",
      "9   70.807258   2.322521       6.0           3.127281\n",
      "10   2.058449  30.377243       6.0         125.729800\n",
      "11        NaN   8.526206       4.0          78.976304\n",
      "12  83.244264   3.252580       6.0          58.697635\n",
      "13  21.233911  47.444277       2.0           2.815965\n",
      "14  18.182497  48.281602       2.0          88.348279\n",
      "15  18.340451  40.419867       4.0         105.652178\n",
      "16        NaN  15.230688       8.0         158.035108\n",
      "17  52.475643   4.883606       NaN         121.191995\n",
      "18  43.194502  34.211651       9.0         151.605920\n",
      "19  29.122914  22.007625       8.0         130.215405\n",
      "\n",
      "\n",
      "Count of missing values after imputation:\n",
      "Feature1             2\n",
      "Feature2             0\n",
      "Feature3             1\n",
      "Feature_to_Impute    0\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question: Predictive Modeling for Imputation\n",
    "# Description: Use a predictive model to impute missing values for a particular feature using other features.\n",
    "\n",
    "# Steps to follow:\n",
    "# 1. Partition the data: Split the dataset into train and test based on the presence of missing values.\n",
    "# 2. Train a model: Use a regression model to predict missing values.\n",
    "# 3. Impute missing values with predictions.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression # Using Linear Regression as the predictive model\n",
    "from sklearn.model_selection import train_test_split # Not for train/test split, but for conceptual partitioning\n",
    "from sklearn.impute import SimpleImputer # Used here to fill NaNs in features before training/predicting\n",
    "\n",
    "# --- Introduction ---\n",
    "# This script demonstrates using a predictive model (Linear Regression)\n",
    "# to impute missing values for a target feature based on other features\n",
    "# in the dataset.\n",
    "#\n",
    "# We will:\n",
    "# 1. Create a sample DataFrame with missing values in a target numerical column.\n",
    "# 2. Partition the data into two sets: one with non-missing target values (for training)\n",
    "#    and one with missing target values (for prediction).\n",
    "# 3. Select features and the target for the imputation model.\n",
    "# 4. Train a Linear Regression model on the training set.\n",
    "# 5. Use the trained model to predict the missing values in the prediction set.\n",
    "# 6. Impute the original DataFrame with the predictions.\n",
    "# 7. Show the DataFrame before and after imputation.\n",
    "\n",
    "# --- 1. Create a Sample DataFrame ---\n",
    "print(\"--- Creating Sample DataFrame ---\")\n",
    "# Create a DataFrame where 'Feature_to_Impute' has missing values\n",
    "# and other features will be used to predict them.\n",
    "np.random.seed(42) # for reproducibility\n",
    "\n",
    "data = {\n",
    "    'Feature1': np.random.rand(20) * 100,\n",
    "    'Feature2': np.random.rand(20) * 50,\n",
    "    'Feature3': np.random.randint(1, 10, size=20),\n",
    "    'Feature_to_Impute': np.random.rand(20) * 200 # Target feature with NaNs\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Introduce missing values in 'Feature_to_Impute'\n",
    "missing_indices = np.random.choice(df.index, size=5, replace=False)\n",
    "df.loc[missing_indices, 'Feature_to_Impute'] = np.nan\n",
    "\n",
    "# Introduce some NaNs in features as well, to show handling\n",
    "df.loc[np.random.choice(df.index, size=2, replace=False), 'Feature1'] = np.nan\n",
    "df.loc[np.random.choice(df.index, size=1, replace=False), 'Feature3'] = np.nan\n",
    "\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Count of missing values before imputation:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Steps to follow: ---\n",
    "\n",
    "# 1. Partition the data: Split the dataset into train and test based on the presence of missing values.\n",
    "print(\"--- Step 1: Partition the data based on missing values ---\")\n",
    "\n",
    "# Create two subsets:\n",
    "# - Data with non-missing values in the target column ('Feature_to_Impute')\n",
    "# - Data with missing values in the target column\n",
    "data_train_imputation = df.dropna(subset=['Feature_to_Impute'])\n",
    "data_predict_imputation = df[df['Feature_to_Impute'].isnull()]\n",
    "\n",
    "print(f\"Data for training imputation model (non-missing target): {len(data_train_imputation)} rows\")\n",
    "print(f\"Data for predicting missing values (missing target): {len(data_predict_imputation)} rows\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Define features (X) and target (y) for the imputation model\n",
    "# Features should ideally not have missing values themselves, or be imputed first.\n",
    "# For simplicity, we'll use SimpleImputer on features before training/prediction.\n",
    "features = ['Feature1', 'Feature2', 'Feature3'] # Features to use for prediction\n",
    "target = 'Feature_to_Impute'\n",
    "\n",
    "X_train_imputation = data_train_imputation[features]\n",
    "y_train_imputation = data_train_imputation[target]\n",
    "\n",
    "X_predict_imputation = data_predict_imputation[features]\n",
    "\n",
    "# Handle missing values in features before training/prediction\n",
    "# Using SimpleImputer (e.g., mean imputation) as a preprocessing step\n",
    "feature_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "X_train_imputation_imputed = feature_imputer.fit_transform(X_train_imputation)\n",
    "X_predict_imputation_imputed = feature_imputer.transform(X_predict_imputation) # Use transform, not fit_transform\n",
    "\n",
    "\n",
    "# 2. Train a model: Use a regression model to predict missing values.\n",
    "print(\"--- Step 2: Train a regression model to predict missing values ---\")\n",
    "\n",
    "# Initialize and train the Linear Regression model\n",
    "imputation_model = LinearRegression()\n",
    "imputation_model.fit(X_train_imputation_imputed, y_train_imputation)\n",
    "\n",
    "print(\"Imputation model (Linear Regression) trained successfully.\")\n",
    "# print(f\"Model Coefficients: {imputation_model.coef_}\")\n",
    "# print(f\"Model Intercept: {imputation_model.intercept_}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# 3. Impute missing values with predictions.\n",
    "print(\"--- Step 3: Impute missing values with predictions ---\")\n",
    "\n",
    "# Predict the missing values using the trained model\n",
    "predicted_values = imputation_model.predict(X_predict_imputation_imputed)\n",
    "\n",
    "print(f\"Predicted {len(predicted_values)} missing values.\")\n",
    "# print(f\"Predicted values: {predicted_values}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Impute the original DataFrame with the predicted values\n",
    "# Create a copy to avoid modifying the original DataFrame directly\n",
    "df_imputed = df.copy()\n",
    "\n",
    "# Get the indices of the rows where the target was missing\n",
    "missing_target_indices = df_imputed[df_imputed[target].isnull()].index\n",
    "\n",
    "# Assign the predicted values to the corresponding locations in the DataFrame\n",
    "df_imputed.loc[missing_target_indices, target] = predicted_values\n",
    "\n",
    "# Note: If there were NaNs in the features that were imputed using SimpleImputer,\n",
    "# you might want to apply that same imputation to the full DataFrame\n",
    "# before or after the predictive imputation step, depending on your workflow.\n",
    "# For simplicity here, we only imputed features *for* the predictive model.\n",
    "# A more complete solution might impute all features first.\n",
    "\n",
    "print(\"DataFrame after Predictive Imputation:\")\n",
    "print(df_imputed)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Count of missing values after imputation:\")\n",
    "print(df_imputed.isnull().sum()) # Should show 0 for the target column if successful\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Conclusion ---\n",
    "# The script successfully used a Linear Regression model trained on rows\n",
    "# with complete target data to predict the missing values in the target column.\n",
    "# These predictions were then used to impute the original DataFrame.\n",
    "# Predictive imputation can capture relationships between features, potentially\n",
    "# leading to more accurate imputation than simple methods like mean/median.\n",
    "# However, it assumes a relationship exists and adds model complexity.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Sample Time Series DataFrame ---\n",
      "Original DataFrame (potentially unsorted):\n",
      "        Date  Value\n",
      "0 2023-01-09   20.0\n",
      "1 2023-01-02   12.0\n",
      "2 2023-01-06    NaN\n",
      "3 2023-01-01   10.0\n",
      "4 2023-01-08   19.0\n",
      "5 2023-01-03    NaN\n",
      "6 2023-01-10   22.0\n",
      "7 2023-01-05   16.0\n",
      "8 2023-01-04   15.0\n",
      "9 2023-01-07    NaN\n",
      "\n",
      "\n",
      "--- Step 2: Sorting the data by Date ---\n",
      "DataFrame sorted by Date:\n",
      "        Date  Value\n",
      "0 2023-01-01   10.0\n",
      "1 2023-01-02   12.0\n",
      "2 2023-01-03    NaN\n",
      "3 2023-01-04   15.0\n",
      "4 2023-01-05   16.0\n",
      "5 2023-01-06    NaN\n",
      "6 2023-01-07    NaN\n",
      "7 2023-01-08   19.0\n",
      "8 2023-01-09   20.0\n",
      "9 2023-01-10   22.0\n",
      "\n",
      "\n",
      "Count of missing values before filling:\n",
      "Date     0\n",
      "Value    3\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "--- Step 3: Applying Forward Fill (ffill) ---\n",
      "DataFrame after Forward Fill:\n",
      "        Date  Value\n",
      "0 2023-01-01   10.0\n",
      "1 2023-01-02   12.0\n",
      "2 2023-01-03   12.0\n",
      "3 2023-01-04   15.0\n",
      "4 2023-01-05   16.0\n",
      "5 2023-01-06   16.0\n",
      "6 2023-01-07   16.0\n",
      "7 2023-01-08   19.0\n",
      "8 2023-01-09   20.0\n",
      "9 2023-01-10   22.0\n",
      "\n",
      "\n",
      "--- Step 4: Applying Backward Fill (bfill) ---\n",
      "DataFrame after Backward Fill:\n",
      "        Date  Value\n",
      "0 2023-01-01   10.0\n",
      "1 2023-01-02   12.0\n",
      "2 2023-01-03   15.0\n",
      "3 2023-01-04   15.0\n",
      "4 2023-01-05   16.0\n",
      "5 2023-01-06   19.0\n",
      "6 2023-01-07   19.0\n",
      "7 2023-01-08   19.0\n",
      "8 2023-01-09   20.0\n",
      "9 2023-01-10   22.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8807/2427139918.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_ffilled['Value'].fillna(method='ffill', inplace=True)\n",
      "/tmp/ipykernel_8807/2427139918.py:62: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_ffilled['Value'].fillna(method='ffill', inplace=True)\n",
      "/tmp/ipykernel_8807/2427139918.py:75: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_bfilled['Value'].fillna(method='bfill', inplace=True)\n",
      "/tmp/ipykernel_8807/2427139918.py:75: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_bfilled['Value'].fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Question: Handling Time Series Data with Forward and Backward Fill\n",
    "# Description: Impute missing values in a time series dataset using forward and backward fill methods.\n",
    "\n",
    "# Steps to follow:\n",
    "# 1. Sort the data: Ensure the dataset is sorted by dates.\n",
    "# 2. Use fillna() with method parameter: Apply ffill() and bfill() for forward and backward fill.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Introduction ---\n",
    "# This script demonstrates how to impute missing values in a time series dataset\n",
    "# using forward fill (ffill) and backward fill (bfill) methods in pandas.\n",
    "# These methods are useful for time series data where the value at a certain\n",
    "# point is likely related to the previous or next values.\n",
    "#\n",
    "# We will:\n",
    "# 1. Create a sample time series DataFrame with missing values.\n",
    "# 2. Ensure the data is sorted by the time index (Date).\n",
    "# 3. Apply forward fill (ffill) to fill NaNs with the previous valid observation.\n",
    "# 4. Apply backward fill (bfill) to fill NaNs with the next valid observation.\n",
    "# 5. Show the DataFrame at each step.\n",
    "\n",
    "# --- 1. Create a Sample Time Series DataFrame ---\n",
    "print(\"--- Creating Sample Time Series DataFrame ---\")\n",
    "# Create a date range\n",
    "dates = pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n",
    "                        '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n",
    "                        '2023-01-09', '2023-01-10'])\n",
    "\n",
    "# Create a numerical series with missing values\n",
    "values = [10, 12, np.nan, 15, 16, np.nan, np.nan, 19, 20, 22]\n",
    "\n",
    "data = {'Date': dates, 'Value': values}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Intentionally shuffle the data to demonstrate the sorting step\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Original DataFrame (potentially unsorted):\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- 2. Sort the data: Ensure the dataset is sorted by dates.\n",
    "print(\"--- Step 2: Sorting the data by Date ---\")\n",
    "df_sorted = df.sort_values(by='Date').reset_index(drop=True)\n",
    "\n",
    "print(\"DataFrame sorted by Date:\")\n",
    "print(df_sorted)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Count of missing values before filling:\")\n",
    "print(df_sorted.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# --- 3. Use fillna() with method='ffill': Apply ffill() for forward fill.\n",
    "print(\"--- Step 3: Applying Forward Fill (ffill) ---\")\n",
    "\n",
    "# Apply ffill. It propagates the last valid observation forward.\n",
    "# Create a copy to keep the original sorted data for bfill\n",
    "df_ffilled = df_sorted.copy()\n",
    "df_ffilled['Value'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "print(\"DataFrame after Forward Fill:\")\n",
    "print(df_ffilled)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# --- 4. Use fillna() with method='bfill': Apply bfill() for backward fill.\n",
    "print(\"--- Step 4: Applying Backward Fill (bfill) ---\")\n",
    "\n",
    "# Apply bfill. It propagates the next valid observation backward.\n",
    "# Use the original sorted data before ffill was applied\n",
    "df_bfilled = df_sorted.copy()\n",
    "df_bfilled['Value'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "print(\"DataFrame after Backward Fill:\")\n",
    "print(df_bfilled)\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Conclusion ---\n",
    "# The script successfully demonstrated using fillna() with method='ffill'\n",
    "# to fill missing values with the previous valid observation and with\n",
    "# method='bfill' to fill with the next valid observation.\n",
    "# Sorting by date is crucial for these methods to work correctly on time series data.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
