{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "   customer_id     name                email            phone   join_date  \\\n",
      "0            1    Alice    alice@example.com   (123) 456-7890  01/15/2023   \n",
      "1            2      Bob             bob@test     123-456-7890  2023-02-01   \n",
      "2            3  Charlie  charlie@example.com          invalid  15-03-2023   \n",
      "3            4    David       david@test.org  +1 234 567 8901    04/01/23   \n",
      "4            5      Eve        invalid-email          5551234  2023-05-15   \n",
      "\n",
      "   age  salary  quantity    zip_code  \n",
      "0   25   50000      10.0       12345  \n",
      "1   -5   60000       5.5  12345-6789  \n",
      "2   30   -1000       3.0     invalid  \n",
      "3  150   75000       8.0       98765  \n",
      "4   42   80000       2.1        1234  \n",
      "Date standardization failed for join_date: time data \"2023-02-01\" doesn't match format \"%m/%d/%Y\", at position 1. You might want to try:\n",
      "    - passing `format` if your strings have a consistent format;\n",
      "    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15712/1012495123.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Original Data:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;31m# Perform standardization and validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0mdf_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize_and_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nStandardized and Validated Data:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15712/1012495123.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'min'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0minvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0minvalid_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minvalid_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                     validation_report = validation_report.append({\n\u001b[0m\u001b[1;32m     73\u001b[0m                         \u001b[0;34m'column'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                         \u001b[0;34m'issue'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mf\"Value < {constraints['min']}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                         \u001b[0;34m'count'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minvalid_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "# Activity 3: Data Standardization & Validation\n",
    "\n",
    "# Task A: Enforcing Data Formats & Constraints\n",
    "\n",
    "# 13. Date Format Standardization:\n",
    "# - Convert all date entries into a uniform format (e.g., YYYY-MM-DD).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 14. Numeric Constraints Enforcement:\n",
    "# - Check and enforce numeric constraints (e.g., age > 0).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 15. String Format Checks:\n",
    "# - Ensure text fields meet certain constraints (e.g., valid email format).\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def standardize_and_validate(df):\n",
    "    \"\"\"\n",
    "    Perform data standardization and validation on a DataFrame\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input dataframe\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Standardized and validated dataframe\n",
    "        pd.DataFrame: Report of validation issues\n",
    "    \"\"\"\n",
    "    # Make a copy of the original dataframe\n",
    "    df_clean = df.copy()\n",
    "    validation_report = pd.DataFrame(columns=['column', 'issue', 'count'])\n",
    "    \n",
    "    # 13. Date Format Standardization\n",
    "    date_columns = [col for col in df.columns if 'date' in col.lower() or 'join' in col.lower()]\n",
    "    for col in date_columns:\n",
    "        try:\n",
    "            df_clean[col] = pd.to_datetime(df_clean[col]).dt.strftime('%Y-%m-%d')\n",
    "            print(f\"Standardized date format for column: {col}\")\n",
    "        except Exception as e:\n",
    "            invalid_count = df_clean[col].isna().sum()\n",
    "            if invalid_count > 0:\n",
    "                validation_report = validation_report.append({\n",
    "                    'column': col,\n",
    "                    'issue': 'Invalid date format',\n",
    "                    'count': invalid_count\n",
    "                }, ignore_index=True)\n",
    "            print(f\"Date standardization failed for {col}: {str(e)}\")\n",
    "    \n",
    "    # 14. Numeric Constraints Enforcement\n",
    "    numeric_constraints = {\n",
    "        'age': {'min': 0, 'max': 120},\n",
    "        'salary': {'min': 0},\n",
    "        'quantity': {'min': 0, 'integer': True}\n",
    "    }\n",
    "    \n",
    "    for col, constraints in numeric_constraints.items():\n",
    "        if col in df_clean.columns:\n",
    "            # Check min/max constraints\n",
    "            if 'min' in constraints:\n",
    "                invalid = df_clean[col] < constraints['min']\n",
    "                invalid_count = invalid.sum()\n",
    "                if invalid_count > 0:\n",
    "                    validation_report = validation_report.append({\n",
    "                        'column': col,\n",
    "                        'issue': f\"Value < {constraints['min']}\",\n",
    "                        'count': invalid_count\n",
    "                    }, ignore_index=True)\n",
    "                    df_clean.loc[invalid, col] = np.nan\n",
    "            \n",
    "            if 'max' in constraints:\n",
    "                invalid = df_clean[col] > constraints['max']\n",
    "                invalid_count = invalid.sum()\n",
    "                if invalid_count > 0:\n",
    "                    validation_report = validation_report.append({\n",
    "                        'column': col,\n",
    "                        'issue': f\"Value > {constraints['max']}\",\n",
    "                        'count': invalid_count\n",
    "                    }, ignore_index=True)\n",
    "                    df_clean.loc[invalid, col] = np.nan\n",
    "            \n",
    "            # Check integer constraint\n",
    "            if constraints.get('integer', False):\n",
    "                non_integer = df_clean[col].dropna().apply(lambda x: not x.is_integer())\n",
    "                invalid_count = non_integer.sum()\n",
    "                if invalid_count > 0:\n",
    "                    validation_report = validation_report.append({\n",
    "                        'column': col,\n",
    "                        'issue': 'Non-integer value',\n",
    "                        'count': invalid_count\n",
    "                    }, ignore_index=True)\n",
    "    \n",
    "    # 15. String Format Checks\n",
    "    string_checks = {\n",
    "        'email': r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$',\n",
    "        'phone': r'^\\+?[\\d\\s\\-\\(\\)]{7,}$',\n",
    "        'zip_code': r'^\\d{5}(-\\d{4})?$'\n",
    "    }\n",
    "    \n",
    "    for col, pattern in string_checks.items():\n",
    "        if col in df_clean.columns:\n",
    "            invalid = ~df_clean[col].astype(str).str.match(pattern, na=True)\n",
    "            invalid_count = invalid.sum()\n",
    "            if invalid_count > 0:\n",
    "                validation_report = validation_report.append({\n",
    "                    'column': col,\n",
    "                    'issue': f'Invalid {col} format',\n",
    "                    'count': invalid_count\n",
    "                }, ignore_index=True)\n",
    "                df_clean.loc[invalid, col] = np.nan\n",
    "    \n",
    "    return df_clean, validation_report\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create sample data\n",
    "    data = {\n",
    "        'customer_id': [1, 2, 3, 4, 5],\n",
    "        'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "        'email': ['alice@example.com', 'bob@test', 'charlie@example.com', 'david@test.org', 'invalid-email'],\n",
    "        'phone': ['(123) 456-7890', '123-456-7890', 'invalid', '+1 234 567 8901', '5551234'],\n",
    "        'join_date': ['01/15/2023', '2023-02-01', '15-03-2023', '04/01/23', '2023-05-15'],\n",
    "        'age': [25, -5, 30, 150, 42],\n",
    "        'salary': [50000, 60000, -1000, 75000, 80000],\n",
    "        'quantity': [10, 5.5, 3, 8, 2.1],\n",
    "        'zip_code': ['12345', '12345-6789', 'invalid', '98765', '1234']\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    print(\"Original Data:\")\n",
    "    print(df)\n",
    "    \n",
    "    # Perform standardization and validation\n",
    "    df_clean, report = standardize_and_validate(df)\n",
    "    \n",
    "    print(\"\\nStandardized and Validated Data:\")\n",
    "    print(df_clean)\n",
    "    \n",
    "    print(\"\\nValidation Issues Found:\")\n",
    "    if not report.empty:\n",
    "        print(report)\n",
    "    else:\n",
    "        print(\"No validation issues found!\")\n",
    "    \n",
    "    # Save cleaned data\n",
    "    df_clean.to_csv('cleaned_data.csv', index=False)\n",
    "    print(\"\\nSaved cleaned data to 'cleaned_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "   customer_id     name                email              phone    join_date  \\\n",
      "0            1    alice       ALICE@test.com       123-456-7890   01/15/2023   \n",
      "1            2      BOB         bob@TEST.com     (123) 456-7890   2023-02-01   \n",
      "2            3  Charlie  CHARLIE@example.COM       123.456.7890   15-03-2023   \n",
      "3            4    dAvId       david@test.org         1234567890  Apr 1, 2023   \n",
      "4            5      EVE      eve@EXAMPLE.org  +1 (234) 567-8901  2023-May-15   \n",
      "\n",
      "  last_purchase_date  \n",
      "0             1/1/23  \n",
      "1         02/15/2023  \n",
      "2      March 5, 2023  \n",
      "3           04-01-23  \n",
      "4         05/15/2023  \n",
      "\n",
      "Standardized Data:\n",
      "   customer_id     name                email              phone    join_date  \\\n",
      "0            1    ALICE       ALICE@TEST.COM     (123) 456-7890   2023-01-15   \n",
      "1            2      BOB         BOB@TEST.COM     (123) 456-7890   2023-02-01   \n",
      "2            3  CHARLIE  CHARLIE@EXAMPLE.COM     (123) 456-7890   2023-03-15   \n",
      "3            4    DAVID       DAVID@TEST.ORG     (123) 456-7890   2023-04-01   \n",
      "4            5      EVE      EVE@EXAMPLE.ORG  +1 (234) 567-8901  2023-May-15   \n",
      "\n",
      "  last_purchase_date  \n",
      "0         2023-01-01  \n",
      "1         2023-02-15  \n",
      "2         2023-03-05  \n",
      "3         2023-04-01  \n",
      "4         2023-05-15  \n",
      "\n",
      "Standardization Report:\n",
      "\n",
      "=== Date Columns ===\n",
      "\n",
      "Column: join_date\n",
      "Action: Custom parsing applied\n",
      "Original samples: ['01/15/2023', '2023-02-01', '15-03-2023', 'Apr 1, 2023', '2023-May-15']\n",
      "Converted samples: ['2023-01-15' '2023-02-01' '2023-03-15' '2023-04-01' '2023-May-15']\n",
      "\n",
      "Column: last_purchase_date\n",
      "Action: Standardized to YYYY-MM-DD\n",
      "Original samples: ['1/1/23', '02/15/2023', 'March 5, 2023', '04-01-23', '05/15/2023']\n",
      "Converted samples: ['2023-01-01' '2023-02-15' '2023-03-05' '2023-04-01' '2023-05-15']\n",
      "\n",
      "=== Phone Columns ===\n",
      "\n",
      "Column: phone\n",
      "Action: Standardized to (XXX) XXX-XXXX format\n",
      "Original samples: ['123-456-7890', '(123) 456-7890', '123.456.7890', '1234567890', '+1 (234) 567-8901']\n",
      "Converted samples: ['(123) 456-7890' '+1 (234) 567-8901']\n",
      "\n",
      "=== Text Columns ===\n",
      "\n",
      "Column: name\n",
      "Action: Converted to uppercase\n",
      "Original samples: ['alice', 'BOB', 'Charlie', 'dAvId', 'EVE']\n",
      "Converted samples: ['ALICE' 'BOB' 'CHARLIE' 'DAVID' 'EVE']\n",
      "\n",
      "Column: email\n",
      "Action: Converted to uppercase\n",
      "Original samples: ['ALICE@test.com', 'bob@TEST.com', 'CHARLIE@example.COM', 'david@test.org', 'eve@EXAMPLE.org']\n",
      "Converted samples: ['ALICE@TEST.COM' 'BOB@TEST.COM' 'CHARLIE@EXAMPLE.COM' 'DAVID@TEST.ORG'\n",
      " 'EVE@EXAMPLE.ORG']\n",
      "\n",
      "Saved standardized data to 'standardized_data.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15712/558802915.py:50: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_clean[col] = pd.to_datetime(df_clean[col], errors='raise')\n"
     ]
    }
   ],
   "source": [
    "# Task B: Addressing Inconsistent Representations\n",
    "\n",
    "# 16. Standardizing Date Formats:\n",
    "# - Identify and correct inconsistent date formats within the dataset.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 17. Pattern Matching for Consistency:\n",
    "# - Standardize phone numbers to a specific pattern (e.g., (123) 456-7890).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 18. Handling Mixed Case Text:\n",
    "# - Convert all text entries to a consistent case (e.g., all uppercase).\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def standardize_data(df):\n",
    "    \"\"\"\n",
    "    Standardize inconsistent data representations in a DataFrame\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input dataframe\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Standardized dataframe\n",
    "        dict: Summary of standardization operations\n",
    "    \"\"\"\n",
    "    # Make a copy of the original dataframe\n",
    "    df_clean = df.copy()\n",
    "    standardization_report = {}\n",
    "    \n",
    "    # 16. Standardizing Date Formats\n",
    "    date_columns = [col for col in df.columns if 'date' in col.lower()]\n",
    "    standardization_report['date_columns'] = {}\n",
    "    \n",
    "    for col in date_columns:\n",
    "        original_values = df_clean[col].astype(str).unique()[:5]  # Sample of original values\n",
    "        try:\n",
    "            # Try to parse dates automatically first\n",
    "            df_clean[col] = pd.to_datetime(df_clean[col], errors='raise')\n",
    "            df_clean[col] = df_clean[col].dt.strftime('%Y-%m-%d')\n",
    "            standardization_report['date_columns'][col] = {\n",
    "                'action': 'Standardized to YYYY-MM-DD',\n",
    "                'sample_original': list(original_values),\n",
    "                'sample_converted': df_clean[col].unique()[:5]\n",
    "            }\n",
    "        except Exception as e:\n",
    "            # Fallback to manual parsing if automatic fails\n",
    "            try:\n",
    "                df_clean[col] = df_clean[col].apply(lambda x: parse_custom_date(x) if pd.notna(x) else x)\n",
    "                standardization_report['date_columns'][col] = {\n",
    "                    'action': 'Custom parsing applied',\n",
    "                    'sample_original': list(original_values),\n",
    "                    'sample_converted': df_clean[col].unique()[:5]\n",
    "                }\n",
    "            except:\n",
    "                standardization_report['date_columns'][col] = {\n",
    "                    'action': 'Failed to standardize',\n",
    "                    'error': str(e),\n",
    "                    'sample_original': list(original_values)\n",
    "                }\n",
    "    \n",
    "    # 17. Pattern Matching for Phone Numbers\n",
    "    phone_columns = [col for col in df.columns if 'phone' in col.lower()]\n",
    "    standardization_report['phone_columns'] = {}\n",
    "    \n",
    "    for col in phone_columns:\n",
    "        original_values = df_clean[col].astype(str).unique()[:5]\n",
    "        df_clean[col] = df_clean[col].apply(standardize_phone_number)\n",
    "        standardization_report['phone_columns'][col] = {\n",
    "            'action': 'Standardized to (XXX) XXX-XXXX format',\n",
    "            'sample_original': list(original_values),\n",
    "            'sample_converted': df_clean[col].unique()[:5]\n",
    "        }\n",
    "    \n",
    "    # 18. Handling Mixed Case Text\n",
    "    text_columns = [col for col in df.columns if df[col].dtype == 'object' and \n",
    "                   col not in date_columns and col not in phone_columns]\n",
    "    standardization_report['text_columns'] = {}\n",
    "    \n",
    "    for col in text_columns:\n",
    "        original_values = df_clean[col].astype(str).unique()[:5]\n",
    "        df_clean[col] = df_clean[col].str.upper()\n",
    "        standardization_report['text_columns'][col] = {\n",
    "            'action': 'Converted to uppercase',\n",
    "            'sample_original': list(original_values),\n",
    "            'sample_converted': df_clean[col].unique()[:5]\n",
    "        }\n",
    "    \n",
    "    return df_clean, standardization_report\n",
    "\n",
    "def parse_custom_date(date_str):\n",
    "    \"\"\"Handle custom date formats that pandas can't automatically parse\"\"\"\n",
    "    if pd.isna(date_str):\n",
    "        return date_str\n",
    "    \n",
    "    # Try common date formats\n",
    "    for fmt in ('%m/%d/%Y', '%d/%m/%Y', '%Y-%m-%d', '%m-%d-%Y', '%d-%m-%Y', \n",
    "                '%b %d, %Y', '%d %b %Y', '%B %d, %Y', '%d %B %Y'):\n",
    "        try:\n",
    "            return datetime.strptime(str(date_str), fmt).strftime('%Y-%m-%d')\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    # If all formats fail, return original (will be marked as invalid)\n",
    "    return date_str\n",
    "\n",
    "def standardize_phone_number(phone):\n",
    "    \"\"\"Standardize phone numbers to (XXX) XXX-XXXX format\"\"\"\n",
    "    if pd.isna(phone):\n",
    "        return phone\n",
    "    \n",
    "    phone_str = str(phone)\n",
    "    # Remove all non-digit characters\n",
    "    digits = re.sub(r'[^\\d]', '', phone_str)\n",
    "    \n",
    "    # Format based on length\n",
    "    if len(digits) == 10:\n",
    "        return f\"({digits[:3]}) {digits[3:6]}-{digits[6:]}\"\n",
    "    elif len(digits) == 11 and digits[0] == '1':  # US country code\n",
    "        return f\"+1 ({digits[1:4]}) {digits[4:7]}-{digits[7:]}\"\n",
    "    else:\n",
    "        return phone_str  # Return original if can't standardize\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create sample data with inconsistent representations\n",
    "    data = {\n",
    "        'customer_id': [1, 2, 3, 4, 5],\n",
    "        'name': ['alice', 'BOB', 'Charlie', 'dAvId', 'EVE'],\n",
    "        'email': ['ALICE@test.com', 'bob@TEST.com', 'CHARLIE@example.COM', 'david@test.org', 'eve@EXAMPLE.org'],\n",
    "        'phone': ['123-456-7890', '(123) 456-7890', '123.456.7890', '1234567890', '+1 (234) 567-8901'],\n",
    "        'join_date': ['01/15/2023', '2023-02-01', '15-03-2023', 'Apr 1, 2023', '2023-May-15'],\n",
    "        'last_purchase_date': ['1/1/23', '02/15/2023', 'March 5, 2023', '04-01-23', '05/15/2023']\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    print(\"Original Data:\")\n",
    "    print(df)\n",
    "    \n",
    "    # Perform standardization\n",
    "    df_clean, report = standardize_data(df)\n",
    "    \n",
    "    print(\"\\nStandardized Data:\")\n",
    "    print(df_clean)\n",
    "    \n",
    "    print(\"\\nStandardization Report:\")\n",
    "    for section, details in report.items():\n",
    "        print(f\"\\n=== {section.replace('_', ' ').title()} ===\")\n",
    "        for col, info in details.items():\n",
    "            print(f\"\\nColumn: {col}\")\n",
    "            print(f\"Action: {info['action']}\")\n",
    "            print(\"Original samples:\", info['sample_original'])\n",
    "            if 'sample_converted' in info:\n",
    "                print(\"Converted samples:\", info['sample_converted'])\n",
    "            if 'error' in info:\n",
    "                print(\"Error:\", info['error'])\n",
    "    \n",
    "    # Save cleaned data\n",
    "    df_clean.to_csv('standardized_data.csv', index=False)\n",
    "    print(\"\\nSaved standardized data to 'standardized_data.csv'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
