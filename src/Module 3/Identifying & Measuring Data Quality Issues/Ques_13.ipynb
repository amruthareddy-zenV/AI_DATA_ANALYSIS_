{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (248928610.py, line 114)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 114\u001b[0;36m\u001b[0m\n\u001b[0;31m    score = max(0, 100 - (max(0, days_old - 7) * 5)\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Metrics & Scoring Examples\n",
    "\n",
    "# Task 1:\n",
    "# Assign scores to a customer dataset based on completeness, uniqueness, and consistency.\n",
    "# Analyze the overall data quality score and identify areas for improvement.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Task 2:\n",
    "# Evaluate a dataset for an online shop using metrics such as accuracy, timeliness, and\n",
    "# integrity. Calculate the data quality score and provide improvement suggestions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Task 3:\n",
    "# Perform a data quality assessment on a financial dataset, scoring it based on validity,\n",
    "# precision, and accessibility. Review the results and propose corrective actions.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "class DataQualityScorer:\n",
    "    \"\"\"A class to assess and score data quality across multiple dimensions\"\"\"\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        self.results = {}\n",
    "        self.weights = {\n",
    "            'completeness': 0.3,\n",
    "            'uniqueness': 0.2,\n",
    "            'consistency': 0.2,\n",
    "            'accuracy': 0.1,\n",
    "            'timeliness': 0.1,\n",
    "            'validity': 0.1\n",
    "        }\n",
    "    \n",
    "    def calculate_completeness(self, critical_columns):\n",
    "        \"\"\"Calculate completeness score (0-100) for critical columns\"\"\"\n",
    "        missing = self.df[critical_columns].isnull().mean().mean()\n",
    "        score = (1 - missing) * 100\n",
    "        self.results['completeness'] = {\n",
    "            'score': score,\n",
    "            'missing_pct': missing * 100,\n",
    "            'critical_columns': critical_columns\n",
    "        }\n",
    "        return score\n",
    "    \n",
    "    def calculate_uniqueness(self, unique_id_columns):\n",
    "        \"\"\"Calculate uniqueness score (0-100)\"\"\"\n",
    "        dup_scores = []\n",
    "        for col in unique_id_columns:\n",
    "            dup_pct = self.df.duplicated(subset=[col]).mean()\n",
    "            dup_scores.append(1 - dup_pct)\n",
    "        score = np.mean(dup_scores) * 100\n",
    "        self.results['uniqueness'] = {\n",
    "            'score': score,\n",
    "            'duplicate_pct': (1 - np.mean(dup_scores)) * 100,\n",
    "            'unique_id_columns': unique_id_columns\n",
    "        }\n",
    "        return score\n",
    "    \n",
    "    def calculate_consistency(self, format_rules):\n",
    "        \"\"\"Calculate consistency score (0-100) based on formatting rules\"\"\"\n",
    "        consistency_scores = []\n",
    "        details = {}\n",
    "        \n",
    "        for col, rule in format_rules.items():\n",
    "            if rule['type'] == 'date':\n",
    "                try:\n",
    "                    pd.to_datetime(self.df[col], format=rule.get('format'))\n",
    "                    consistency_scores.append(1)\n",
    "                    details[col] = 'consistent'\n",
    "                except:\n",
    "                    consistency_scores.append(0)\n",
    "                    details[col] = 'inconsistent'\n",
    "            \n",
    "            elif rule['type'] == 'regex':\n",
    "                matches = self.df[col].astype(str).str.match(rule['pattern'], na=False)\n",
    "                consistency_scores.append(matches.mean())\n",
    "                details[col] = f\"{matches.mean()*100:.1f}% match\"\n",
    "        \n",
    "        score = np.mean(consistency_scores) * 100\n",
    "        self.results['consistency'] = {\n",
    "            'score': score,\n",
    "            'details': details,\n",
    "            'format_rules': format_rules\n",
    "        }\n",
    "        return score\n",
    "    \n",
    "    def calculate_accuracy(self, verifiable_columns, reference_data=None):\n",
    "        \"\"\"Calculate accuracy score (0-100)\"\"\"\n",
    "        # This would typically involve comparison with reference data\n",
    "        # For demo purposes, we'll assume 95% accuracy\n",
    "        score = 95  # Placeholder - implement actual verification logic\n",
    "        self.results['accuracy'] = {\n",
    "            'score': score,\n",
    "            'verifiable_columns': verifiable_columns,\n",
    "            'method': 'Compared with reference dataset' if reference_data else 'Sampling verification'\n",
    "        }\n",
    "        return score\n",
    "    \n",
    "    def calculate_timeliness(self, date_column):\n",
    "        \"\"\"Calculate timeliness score (0-100) based on data freshness\"\"\"\n",
    "        today = pd.to_datetime(datetime.now().date())\n",
    "        max_date = pd.to_datetime(self.df[date_column]).max()\n",
    "        days_old = (today - max_date).days\n",
    "        \n",
    "        # Score decays linearly after 7 days (customize as needed)\n",
    "        score = max(0, 100 - (max(0, days_old - 7) * 5)\n",
    "        self.results['timeliness'] = {\n",
    "            'score': score,\n",
    "            'days_since_last_update': days_old,\n",
    "            'date_column': date_column\n",
    "        }\n",
    "        return score\n",
    "    \n",
    "    def calculate_validity(self, validation_rules):\n",
    "        \"\"\"Calculate validity score (0-100) based on business rules\"\"\"\n",
    "        valid_scores = []\n",
    "        details = {}\n",
    "        \n",
    "        for col, rules in validation_rules.items():\n",
    "            col_valid = []\n",
    "            for rule in rules:\n",
    "                if rule['type'] == 'range':\n",
    "                    valid = self.df[col].between(rule['min'], rule['max'])\n",
    "                elif rule['type'] == 'values':\n",
    "                    valid = self.df[col].isin(rule['values'])\n",
    "                col_valid.append(valid.mean())\n",
    "            \n",
    "            col_score = np.mean(col_valid) * 100\n",
    "            valid_scores.append(col_score)\n",
    "            details[col] = f\"{col_score:.1f}% valid\"\n",
    "        \n",
    "        score = np.mean(valid_scores)\n",
    "        self.results['validity'] = {\n",
    "            'score': score,\n",
    "            'details': details,\n",
    "            'validation_rules': validation_rules\n",
    "        }\n",
    "        return score\n",
    "    \n",
    "    def calculate_overall_score(self):\n",
    "        \"\"\"Calculate weighted overall data quality score\"\"\"\n",
    "        total = 0\n",
    "        max_possible = 0\n",
    "        \n",
    "        for dimension, weight in self.weights.items():\n",
    "            if dimension in self.results:\n",
    "                total += self.results[dimension]['score'] * weight\n",
    "                max_possible += 100 * weight\n",
    "        \n",
    "        overall_score = (total / max_possible) * 100 if max_possible > 0 else 0\n",
    "        self.results['overall_score'] = overall_score\n",
    "        return overall_score\n",
    "    \n",
    "    def generate_report(self):\n",
    "        \"\"\"Generate a comprehensive data quality report\"\"\"\n",
    "        report = []\n",
    "        \n",
    "        # Header\n",
    "        report.append(\"=\"*50)\n",
    "        report.append(\"DATA QUALITY ASSESSMENT REPORT\")\n",
    "        report.append(\"=\"*50)\n",
    "        report.append(f\"\\nOverall Data Quality Score: {self.results['overall_score']:.1f}/100\")\n",
    "        \n",
    "        # Dimension details\n",
    "        for dimension in self.weights.keys():\n",
    "            if dimension in self.results:\n",
    "                report.append(f\"\\n{dimension.upper()} ({self.weights[dimension]*100}% weight)\")\n",
    "                report.append(\"-\"*50)\n",
    "                \n",
    "                dim_data = self.results[dimension]\n",
    "                if dimension == 'completeness':\n",
    "                    report.append(f\"Score: {dim_data['score']:.1f}\")\n",
    "                    report.append(f\"Missing data: {dim_data['missing_pct']:.1f}% in critical columns\")\n",
    "                    report.append(f\"Critical columns: {', '.join(dim_data['critical_columns'])}\")\n",
    "                \n",
    "                elif dimension == 'uniqueness':\n",
    "                    report.append(f\"Score: {dim_data['score']:.1f}\")\n",
    "                    report.append(f\"Duplicate values: {dim_data['duplicate_pct']:.1f}% in ID columns\")\n",
    "                    report.append(f\"Unique ID columns: {', '.join(dim_data['unique_id_columns'])}\")\n",
    "                \n",
    "                elif dimension == 'consistency':\n",
    "                    report.append(f\"Score: {dim_data['score']:.1f}\")\n",
    "                    report.append(\"Format compliance details:\")\n",
    "                    for col, detail in dim_data['details'].items():\n",
    "                        report.append(f\"  - {col}: {detail}\")\n",
    "                \n",
    "                elif dimension == 'accuracy':\n",
    "                    report.append(f\"Score: {dim_data['score']:.1f} (estimated)\")\n",
    "                    report.append(f\"Verified columns: {', '.join(dim_data['verifiable_columns'])}\")\n",
    "                    report.append(f\"Method: {dim_data['method']}\")\n",
    "                \n",
    "                elif dimension == 'timeliness':\n",
    "                    report.append(f\"Score: {dim_data['score']:.1f}\")\n",
    "                    report.append(f\"Days since last update: {dim_data['days_since_last_update']}\")\n",
    "                    report.append(f\"Date column used: {dim_data['date_column']}\")\n",
    "                \n",
    "                elif dimension == 'validity':\n",
    "                    report.append(f\"Score: {dim_data['score']:.1f}\")\n",
    "                    report.append(\"Validation results:\")\n",
    "                    for col, detail in dim_data['details'].items():\n",
    "                        report.append(f\"  - {col}: {detail}\")\n",
    "        \n",
    "        # Recommendations\n",
    "        report.append(\"\\nRECOMMENDATIONS\")\n",
    "        report.append(\"-\"*50)\n",
    "        \n",
    "        if 'completeness' in self.results and self.results['completeness']['score'] < 90:\n",
    "            report.append(\"- Implement data validation rules to prevent missing data entry\")\n",
    "            report.append(\"- Add data imputation for historical missing values\")\n",
    "        \n",
    "        if 'uniqueness' in self.results and self.results['uniqueness']['score'] < 95:\n",
    "            report.append(\"- Establish duplicate detection processes\")\n",
    "            report.append(\"- Implement unique constraints in database\")\n",
    "        \n",
    "        if 'consistency' in self.results and self.results['consistency']['score'] < 85:\n",
    "            report.append(\"- Standardize data formats with input validation\")\n",
    "            report.append(\"- Create data transformation pipelines for existing inconsistent data\")\n",
    "        \n",
    "        return \"\\n\".join(report)\n",
    "\n",
    "# Example Usage for Different Scenarios\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample customer data\n",
    "    customer_data = {\n",
    "        'customer_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'email': ['a@test.com', 'b@test.com', None, 'd@test.com', 'e@test.com', \n",
    "                 'f@test.com', None, 'h@test.com', 'i@test.com', 'j@test.com'],\n",
    "        'join_date': ['2023-01-01', '2023-02-15', '2023-03-10', '2023-04-05', \n",
    "                     '2023-05-20', None, '2023-07-01', '2023-08-15', '2023-09-10', None],\n",
    "        'phone': ['(123) 456-7890', '123-456-7890', '1234567890', '(987) 654-3210', \n",
    "                 '987 654 3210', '555-1234', 'invalid', '(111) 222-3333', '444.555.6666', '7778889999'],\n",
    "        'status': ['active', 'inactive', 'active', 'pending', 'active', \n",
    "                  'closed', 'active', 'pending', 'inactive', 'active'],\n",
    "        'last_purchase': pd.date_range('2023-01-01', periods=10, freq='30D')\n",
    "    }\n",
    "    customer_df = pd.DataFrame(customer_data)\n",
    "    \n",
    "    print(\"\\nCUSTOMER DATA QUALITY ASSESSMENT\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Task 1: Customer Data Scoring\n",
    "    customer_scorer = DataQualityScorer(customer_df)\n",
    "    customer_scorer.calculate_completeness(['email', 'join_date'])\n",
    "    customer_scorer.calculate_uniqueness(['customer_id'])\n",
    "    customer_scorer.calculate_consistency({\n",
    "        'phone': {'type': 'regex', 'pattern': r'^\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}$'},\n",
    "        'join_date': {'type': 'date', 'format': '%Y-%m-%d'}\n",
    "    })\n",
    "    customer_scorer.calculate_validity({\n",
    "        'status': [{'type': 'values', 'values': ['active', 'inactive', 'pending', 'closed']}]\n",
    "    })\n",
    "    customer_scorer.calculate_timeliness('last_purchase')\n",
    "    customer_scorer.calculate_overall_score()\n",
    "    print(customer_scorer.generate_report())\n",
    "    \n",
    "    # Task 2: E-commerce Data Scoring (sample implementation)\n",
    "    print(\"\\n\\nONLINE SHOP DATA QUALITY ASSESSMENT\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # This would use similar methods with different columns/rules\n",
    "    # Implement based on actual e-commerce dataset\n",
    "    \n",
    "    # Task 3: Financial Data Scoring (sample implementation)\n",
    "    print(\"\\n\\nFINANCIAL DATA QUALITY ASSESSMENT\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # This would use similar methods with financial-specific validation rules\n",
    "    # Implement based on actual financial dataset\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
