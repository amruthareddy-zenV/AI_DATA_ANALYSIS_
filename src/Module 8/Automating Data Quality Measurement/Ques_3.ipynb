{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using AI for Anomalies Detection in Data Quality\n",
    "**Description**: Implement an AI-based approach to detect anomalies in data quality.\n",
    "\n",
    "**Steps**:\n",
    "1. Use an Anomaly Detection Algorithm:\n",
    "    - Use sklearn's Isolation Forest for anomaly detection.\n",
    "\n",
    "**Example data:**\n",
    "\n",
    "data = np.array([[25, 50000], [30, 60000], [35, 75000], [40, None], [45, 100000]])\n",
    "\n",
    "2. Integrate with Great Expectations:\n",
    "    - Generate alerts if anomalies are detected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'great_expectations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IsolationForest\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileDataContext\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Validator\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 1. Prepare the data\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'great_expectations'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from great_expectations.data_context import FileDataContext\n",
    "from great_expectations.validator.validator import Validator\n",
    "\n",
    "# 1. Prepare the data\n",
    "data = np.array([[25, 50000],\n",
    "                 [30, 60000],\n",
    "                 [35, 75000],\n",
    "                 [40, None],\n",
    "                 [45, 100000],\n",
    "                 [28, 55000],\n",
    "                 [60, 15000],  # Potential anomaly\n",
    "                 [32, 70000],\n",
    "                 [50, 120000], # Potential anomaly\n",
    "                 [38, None]])\n",
    "\n",
    "df = pd.DataFrame(data, columns=['feature1', 'feature2'])\n",
    "\n",
    "# Handle missing values for Isolation Forest (replace None with NaN)\n",
    "df_filled = df.fillna(np.nan)\n",
    "\n",
    "# 2. Train the Anomaly Detection Model (Isolation Forest)\n",
    "model = IsolationForest(contamination='auto', random_state=42)\n",
    "model.fit(df_filled)\n",
    "\n",
    "# Predict anomalies (-1 for anomaly, 1 for inlier)\n",
    "anomaly_scores = model.decision_function(df_filled)\n",
    "anomaly_predictions = model.predict(df_filled)\n",
    "\n",
    "# Add anomaly information back to the DataFrame\n",
    "df['anomaly_score'] = anomaly_scores\n",
    "df['is_anomaly'] = anomaly_predictions == -1\n",
    "\n",
    "print(\"Data with Anomaly Scores and Predictions:\")\n",
    "print(df)\n",
    "\n",
    "# 3. Integrate with Great Expectations\n",
    "# Initialize Data Context (if you haven't already)\n",
    "# Assuming you have a Great Expectations project initialized.\n",
    "# If not, you can initialize one using:\n",
    "# from great_expectations.cli import init\n",
    "# init --interactive\n",
    "\n",
    "context = FileDataContext.create(\n",
    "    project_root_dir='great_expectations',  # Replace with your project directory\n",
    ")\n",
    "\n",
    "# Create a Pandas Datasource\n",
    "datasource_name = \"pandas_anomaly_data\"\n",
    "if datasource_name not in context.list_datasources():\n",
    "    context.add_pandas(name=datasource_name, batch_kwargs_generators={\n",
    "        \"default\": {\n",
    "            \"class_name\": \"BatchKwargsGenerator\",\n",
    "            \"datasource_name\": datasource_name,\n",
    "            \"method_name\": \"add_dataframe\",\n",
    "            \"kwargs\": {\n",
    "                \"df\": df,\n",
    "                \"batch_kwargs\": {\"table\": \"anomaly_data\"},\n",
    "            },\n",
    "        }\n",
    "    })\n",
    "\n",
    "# Create a Validator\n",
    "batch = context.get_validator(\n",
    "    datasource_name=datasource_name,\n",
    "    data_connector_name=\"default\",\n",
    "    data_asset_name=\"anomaly_data\",\n",
    ")\n",
    "\n",
    "# Define Expectations for Data Quality (including anomaly detection)\n",
    "batch.expect_column_values_to_not_be_null(column='feature1')\n",
    "# We can't directly \"expect_anomalies\" with built-in GE, so we'll check the 'is_anomaly' column\n",
    "\n",
    "# Expectation: No anomalies should be present (ideally)\n",
    "batch.expect_column_values_to_equal(column='is_anomaly', value=False, mostly=0.95)\n",
    "# 'mostly' allows for a small percentage of anomalies\n",
    "\n",
    "# Run the validation\n",
    "results = batch.validate()\n",
    "\n",
    "print(\"\\nGreat Expectations Validation Results:\")\n",
    "print(results.to_json_dict())\n",
    "\n",
    "# 4. Generate Alerts if Anomalies are Detected (based on GE validation)\n",
    "if not results[\"success\"]:\n",
    "    print(\"\\nPotential Data Quality Anomalies Detected by AI and Reported by Great Expectations:\")\n",
    "    for expectation_result in results[\"results\"]:\n",
    "        if not expectation_result[\"success\"]:\n",
    "            print(f\"  - Expectation '{expectation_result['expectation_config']['expectation_type']}' failed: {expectation_result['result']}\")\n",
    "    print(\"\\nReview the 'is_anomaly' column in the data for specific instances flagged by the AI model.\")\n",
    "else:\n",
    "    print(\"\\nNo data quality anomalies detected based on the defined expectations.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
